{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# Preprocessing\n\nThe data is in a tfrec format which is suitable to be used with a TPU. The data will be changed to .jpeg format to be usaed on a GPU.","metadata":{}},{"cell_type":"code","source":"#Import libraries\nimport torch \nimport torchvision\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch import nn, optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport glob\nimport tensorflow as tf\nAUTO = tf.data.experimental.AUTOTUNE\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:02.153385Z","iopub.execute_input":"2022-02-11T09:42:02.153741Z","iopub.status.idle":"2022-02-11T09:42:02.163624Z","shell.execute_reply.started":"2022-02-11T09:42:02.153707Z","shell.execute_reply":"2022-02-11T09:42:02.162540Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)  # image format uint8 [0,255]\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\ndef data_augment(image, label):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    #image = tf.image.random_saturation(image, 0, 2)\n    return image, label   \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    #dataset = dataset.map(data_augment)\n    #dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    #dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:03.394079Z","iopub.execute_input":"2022-02-11T09:42:03.394387Z","iopub.status.idle":"2022-02-11T09:42:03.412653Z","shell.execute_reply.started":"2022-02-11T09:42:03.394351Z","shell.execute_reply":"2022-02-11T09:42:03.411502Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [224, 224]\nBATCH_SIZE = 16 \n\nPATH_SELECT = { # available image sizes\n    192: '../input/dataset' + '/tfrecords-jpeg-192x192',\n    224: '../input/dataset' + '/tfrecords-jpeg-224x224',\n    331: '../input/dataset' + '/tfrecords-jpeg-331x331',\n    512: '../input/dataset' + '/tfrecords-jpeg-512x512'\n}\n\nPATH = PATH_SELECT[224]\n\nTRAINING_FILENAMES = tf.io.gfile.glob(PATH + '/train/*.tfrec')\nVALIDATION_FILENAMES = tf.io.gfile.glob(PATH + '/val/*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(PATH + '/test/*.tfrec')","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:44:10.232767Z","iopub.execute_input":"2022-02-11T09:44:10.233585Z","iopub.status.idle":"2022-02-11T09:44:10.270444Z","shell.execute_reply.started":"2022-02-11T09:44:10.233545Z","shell.execute_reply":"2022-02-11T09:44:10.269673Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"dataset = get_training_dataset()\nimages = []\nlabels = []\n\nfor img, lbl in dataset:\n    images.append(img)\n    labels.append(lbl)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:44:11.190499Z","iopub.execute_input":"2022-02-11T09:44:11.190842Z","iopub.status.idle":"2022-02-11T09:44:19.471317Z","shell.execute_reply.started":"2022-02-11T09:44:11.190805Z","shell.execute_reply":"2022-02-11T09:44:19.470206Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"img_list=[]\nfor i in range(images.__len__()):\n    for j in range(images[i].__len__()):\n        img_list.append(images[i][j,:,:,:])\n        \nlab_list = list()\nfor label in labels:\n    x = label.numpy().tolist()\n    lab_list+=x","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:44:23.326124Z","iopub.execute_input":"2022-02-11T09:44:23.327072Z","iopub.status.idle":"2022-02-11T09:44:25.118000Z","shell.execute_reply.started":"2022-02-11T09:44:23.327028Z","shell.execute_reply":"2022-02-11T09:44:25.116937Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:44:28.226230Z","iopub.execute_input":"2022-02-11T09:44:28.226561Z","iopub.status.idle":"2022-02-11T09:44:28.231342Z","shell.execute_reply.started":"2022-02-11T09:44:28.226525Z","shell.execute_reply":"2022-02-11T09:44:28.230306Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"for i in range(len(lab_list)):\n    img = np.array(img_list[i]).astype(np.uint8)\n    lbl = lab_list[i]\n    lbl = str(lbl)\n    if not os.path.exists(\"./dataset224/train/\"+lbl):\n        os.makedirs(\"./dataset224/train/\"+lbl)\n    im = Image.fromarray(img)\n    im.save(\"./dataset224/train/\"+lbl+\"/\"+str(i)+\".jpeg\")","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:44:42.420556Z","iopub.execute_input":"2022-02-11T09:44:42.420882Z","iopub.status.idle":"2022-02-11T09:45:13.084083Z","shell.execute_reply.started":"2022-02-11T09:44:42.420846Z","shell.execute_reply":"2022-02-11T09:45:13.083054Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"dataset = get_validation_dataset()\nval_images = []\nval_labels = []\n\nfor img, lbl in dataset:\n    val_images.append(img)\n    val_labels.append(lbl)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:45:55.262203Z","iopub.execute_input":"2022-02-11T09:45:55.262919Z","iopub.status.idle":"2022-02-11T09:45:58.735069Z","shell.execute_reply.started":"2022-02-11T09:45:55.262864Z","shell.execute_reply":"2022-02-11T09:45:58.734335Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"val_img_list=[]\nfor i in range(val_images.__len__()):\n    for j in range(val_images[i].__len__()):\n        img_list.append(val_images[i][j,:,:,:])\n        \nval_lab_list = list()\nfor label in val_labels:\n    x = label.numpy().tolist()\n    val_lab_list+=x","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:46:08.387705Z","iopub.execute_input":"2022-02-11T09:46:08.388456Z","iopub.status.idle":"2022-02-11T09:46:08.928426Z","shell.execute_reply.started":"2022-02-11T09:46:08.388415Z","shell.execute_reply":"2022-02-11T09:46:08.927375Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"for i in range(len(lab_list)):\n    img = np.array(img_list[i]).astype(np.uint8)\n    lbl = lab_list[i]\n    lbl = str(lbl)\n    if not os.path.exists(\"./dataset224/val/\"+lbl):\n        os.makedirs(\"./dataset224/val/\"+lbl)\n    im = Image.fromarray(img)\n    im.save(\"./dataset224/val/\"+lbl+\"/\"+str(i)+\".jpeg\")","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:46:13.137918Z","iopub.execute_input":"2022-02-11T09:46:13.138735Z","iopub.status.idle":"2022-02-11T09:46:43.580891Z","shell.execute_reply.started":"2022-02-11T09:46:13.138686Z","shell.execute_reply":"2022-02-11T09:46:43.579860Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}