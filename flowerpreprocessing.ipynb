{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# Preprocessing\n\nThe data is in a tfrec format which is suitable to be used with a TPU. The data will be changed to .jpeg format to be usaed on a GPU.","metadata":{}},{"cell_type":"code","source":"#Import libraries\nimport torch \nimport torchvision\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch import nn, optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport glob\nimport tensorflow as tf\nAUTO = tf.data.experimental.AUTOTUNE\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:02.153385Z","iopub.execute_input":"2022-02-11T09:42:02.153741Z","iopub.status.idle":"2022-02-11T09:42:02.163624Z","shell.execute_reply.started":"2022-02-11T09:42:02.153707Z","shell.execute_reply":"2022-02-11T09:42:02.162540Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)  # image format uint8 [0,255]\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\ndef data_augment(image, label):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    #image = tf.image.random_saturation(image, 0, 2)\n    return image, label   \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    #dataset = dataset.map(data_augment)\n    #dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    #dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:03.394079Z","iopub.execute_input":"2022-02-11T09:42:03.394387Z","iopub.status.idle":"2022-02-11T09:42:03.412653Z","shell.execute_reply.started":"2022-02-11T09:42:03.394351Z","shell.execute_reply":"2022-02-11T09:42:03.411502Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [224, 224]\nBATCH_SIZE = 16 \n\nPATH_SELECT = { # available image sizes\n    192: './data' + '/tfrecords-jpeg-192x192',\n    224: './data' + '/tfrecords-jpeg-224x224',\n    331: './data' + '/tfrecords-jpeg-331x331',\n    512: './data' + '/tfrecords-jpeg-512x512'\n}\n\nPATH = PATH_SELECT[224]\n\nTRAINING_FILENAMES = tf.io.gfile.glob(PATH + '/train/*.tfrec')\nVALIDATION_FILENAMES = tf.io.gfile.glob(PATH + '/val/*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(PATH + '/test/*.tfrec')","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:03.952381Z","iopub.execute_input":"2022-02-11T09:42:03.952704Z","iopub.status.idle":"2022-02-11T09:42:03.960220Z","shell.execute_reply.started":"2022-02-11T09:42:03.952669Z","shell.execute_reply":"2022-02-11T09:42:03.959115Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dataset = get_training_dataset()\nimages = []\nlabels = []\n\nfor img, lbl in dataset:\n    images.append(img)\n    labels.append(lbl)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:04.477453Z","iopub.execute_input":"2022-02-11T09:42:04.478144Z","iopub.status.idle":"2022-02-11T09:42:04.576824Z","shell.execute_reply.started":"2022-02-11T09:42:04.478098Z","shell.execute_reply":"2022-02-11T09:42:04.575886Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"img_list=[]\nfor i in range(images.__len__()):\n    for j in range(images[i].__len__()):\n        img_list.append(images[i][j,:,:,:])\n        \nlab_list = list()\nfor label in labels:\n    x = label.numpy().tolist()\n    lab_list+=x","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:05.387533Z","iopub.execute_input":"2022-02-11T09:42:05.388284Z","iopub.status.idle":"2022-02-11T09:42:05.394281Z","shell.execute_reply.started":"2022-02-11T09:42:05.388241Z","shell.execute_reply":"2022-02-11T09:42:05.393216Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:06.112803Z","iopub.execute_input":"2022-02-11T09:42:06.113102Z","iopub.status.idle":"2022-02-11T09:42:06.116981Z","shell.execute_reply.started":"2022-02-11T09:42:06.113064Z","shell.execute_reply":"2022-02-11T09:42:06.116285Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for i in range(len(lab_list)):\n    img = np.array(img_list[i]).astype(np.uint8)\n    lbl = lab_list[i]\n    lbl = str(lbl)\n    if not os.path.exists(\"./dataset224/train/\"+lbl):\n        os.makedirs(\"./dataset224/train/\"+lbl)\n    im = Image.fromarray(img)\n    im.save(\"./dataset224/train/\"+lbl+\"/\"+str(i)+\".jpeg\")","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:06.693314Z","iopub.execute_input":"2022-02-11T09:42:06.694066Z","iopub.status.idle":"2022-02-11T09:42:06.700763Z","shell.execute_reply.started":"2022-02-11T09:42:06.694023Z","shell.execute_reply":"2022-02-11T09:42:06.699785Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"dataset = get_validation_dataset()\nval_images = []\nval_labels = []\n\nfor img, lbl in dataset:\n    val_images.append(img)\n    val_labels.append(lbl)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:07.468603Z","iopub.execute_input":"2022-02-11T09:42:07.469281Z","iopub.status.idle":"2022-02-11T09:42:07.611531Z","shell.execute_reply.started":"2022-02-11T09:42:07.469246Z","shell.execute_reply":"2022-02-11T09:42:07.610556Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"val_img_list=[]\nfor i in range(val_images.__len__()):\n    for j in range(val_images[i].__len__()):\n        img_list.append(val_images[i][j,:,:,:])\n        \nval_lab_list = list()\nfor label in val_labels:\n    x = label.numpy().tolist()\n    val_lab_list+=x","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:07.942651Z","iopub.execute_input":"2022-02-11T09:42:07.942946Z","iopub.status.idle":"2022-02-11T09:42:07.948944Z","shell.execute_reply.started":"2022-02-11T09:42:07.942912Z","shell.execute_reply":"2022-02-11T09:42:07.947939Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for i in range(len(lab_list)):\n    img = np.array(img_list[i]).astype(np.uint8)\n    lbl = lab_list[i]\n    lbl = str(lbl)\n    if not os.path.exists(\"./dataset224/val/\"+lbl):\n        os.makedirs(\"./dataset224/val/\"+lbl)\n    im = Image.fromarray(img)\n    im.save(\"./dataset224/val/\"+lbl+\"/\"+str(i)+\".jpeg\")","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:08.445584Z","iopub.execute_input":"2022-02-11T09:42:08.445869Z","iopub.status.idle":"2022-02-11T09:42:08.452149Z","shell.execute_reply.started":"2022-02-11T09:42:08.445839Z","shell.execute_reply":"2022-02-11T09:42:08.451253Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}