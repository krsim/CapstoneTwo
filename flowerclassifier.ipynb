{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Models\n\n","metadata":{}},{"cell_type":"markdown","source":"\n# Table of Contents\n1. [Introduction](#introduction)\n2. [Import Libraries](#libraries)\n3. [Distribution Strategy](#strategy)\n4. [Load Data](#load)\n5. [Some Helper Functions](#functions)\n6. [Get Datasets Ready For Training](#datasets)\n7. [Define and Train Models](#models)\n    1. [VGG](#vgg)\n    2. [Resnet50](#resnet)\n    3. [InceptionNet V3](#inception)\n8. [Evaluate Models](#evaluate)\n    1. [Training Curves](#curves)\n    2. [Confusion Matrix](#matrix)\n        1. [VGG](#vggmatrix)\n        2. [Resnet50](#resnetmatrix)\n        3. [InceptionNet V3](#inceptionmatrix)","metadata":{}},{"cell_type":"markdown","source":"\n## Introduction <a name=introduction>\n    \n    In this notebook, the data is uploaded from Kaggle dataset and stored in a Google Coud Storage bucket to be used with TPUs. The data itself is in a tfrec format for convenient distribution to the TPU cores.\n\nThe final layers of three pretrained networks are trained on the data and the results are compared in the next notebook. ","metadata":{}},{"cell_type":"markdown","source":"\n## Import libraries <a name=\"libraries\">","metadata":{}},{"cell_type":"code","source":"import math, re, os\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:55:01.923458Z","iopub.execute_input":"2022-03-10T20:55:01.924054Z","iopub.status.idle":"2022-03-10T20:55:07.953466Z","shell.execute_reply.started":"2022-03-10T20:55:01.923962Z","shell.execute_reply":"2022-03-10T20:55:07.952638Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2022-03-10 20:55:02.596696: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-03-10 20:55:02.596855: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"},{"name":"stdout","text":"Tensorflow version 2.4.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n## Distribution Strategy <a name=\"strategy\">","metadata":{}},{"cell_type":"code","source":"# Detect TPU, return distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(\"Running on TPU \", tpu.master())\nexcept ValueError:\n    tpu = None\n    \nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n    \nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:55:17.704654Z","iopub.execute_input":"2022-03-10T20:55:17.705844Z","iopub.status.idle":"2022-03-10T20:55:23.372270Z","shell.execute_reply.started":"2022-03-10T20:55:17.705801Z","shell.execute_reply":"2022-03-10T20:55:23.371414Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Running on TPU  grpc://10.0.0.2:8470\n","output_type":"stream"},{"name":"stderr","text":"2022-03-10 20:55:17.714424: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-03-10 20:55:17.717120: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-03-10 20:55:17.717150: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2022-03-10 20:55:17.717177: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ceab6ebf4157): /proc/driver/nvidia/version does not exist\n2022-03-10 20:55:17.720766: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-03-10 20:55:17.722610: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-03-10 20:55:17.757333: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2022-03-10 20:55:17.757392: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30042}\n2022-03-10 20:55:17.777672: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2022-03-10 20:55:17.777728: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30042}\n2022-03-10 20:55:17.779235: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30042\n","output_type":"stream"},{"name":"stdout","text":"REPLICAS:  8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n## Load Data <a name=\"load\">","metadata":{}},{"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')\nprint(GCS_DS_PATH) ","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:55:27.667756Z","iopub.execute_input":"2022-03-10T20:55:27.668016Z","iopub.status.idle":"2022-03-10T20:55:28.171848Z","shell.execute_reply.started":"2022-03-10T20:55:27.667990Z","shell.execute_reply":"2022-03-10T20:55:28.170892Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"gs://kds-25a6b94c18cfd3583127cd2061d45429c97ce8c321dc19ba3085e826\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\ndirs = os.listdir(\"../input\")\n\nfor file in dirs:\n    print(file)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:55:31.769313Z","iopub.execute_input":"2022-03-10T20:55:31.769872Z","iopub.status.idle":"2022-03-10T20:55:31.776909Z","shell.execute_reply.started":"2022-03-10T20:55:31.769826Z","shell.execute_reply":"2022-03-10T20:55:31.775968Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"tpu-getting-started\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The Kaggle data is split into a labeled training set, a labeled validation set, and an unlabeled test set. The unlabeled set is used for competition submission and will not be used here. Instead, the validation set will be used as the test set and the training set will be split for validation.","metadata":{}},{"cell_type":"code","source":"\nIMAGE_SIZE = [224, 224]\nGCS_PATH =  GCS_DS_PATH + '/tfrecords-jpeg-224x224'\nAUTO = tf.data.experimental.AUTOTUNE\n\nvalidation_split = 0.25\ndata_files = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\nsplit = len(data_files) - int(len(data_files) * validation_split)\n\nTRAINING_FILENAMES = data_files[:split]\nVALIDATION_FILENAMES = data_files[split:]\nTEST_FILENAMES =  tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n\nCLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102\n\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:06:51.969457Z","iopub.execute_input":"2022-03-10T21:06:51.969937Z","iopub.status.idle":"2022-03-10T21:06:52.142281Z","shell.execute_reply.started":"2022-03-10T21:06:51.969888Z","shell.execute_reply":"2022-03-10T21:06:52.141380Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"2022-03-10 21:06:51.987126: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n2022-03-10 21:06:52.061227: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n## Helper Functions <a name=\"functions\">\n\nFunctions to augment and retrieve data","metadata":{}},{"cell_type":"code","source":"def zoom(x: tf.Tensor) -> tf.Tensor:\n    #Zoom Augmentation\n    \n    scales = list(np.arange(0.8, 1.2, 0.02))\n    boxes = np.zeros((len(scales), 4))\n    \n    for i, scale in enumerate(scales):\n        x1 = y1 = 0.5 - (0.5 * scale)\n        x2 = y2 = 0.5 + (0.5 * scale)\n        boxes[i] = [x1, y1, x2, y2]\n        \n    def random_crop(img):\n        #Create different crops\n        crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=(224, 224) )\n        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n    \n    choice =  tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n    \n    #Applies 50% of the time\n    return tf.cond(choice < 0.5, lambda: x, lambda: random_crop(x))\n\n\ndef rotate(x: tf.Tensor) -> tf.Tensor:\n    \n    image = tf.cond(tf.greater(tf.random.uniform([]), 0.5), lambda: tf.image.rot90(x), lambda: x)\n    return image\n\ndef data_augment(image, label):\n    #Execute a series of random image augmentations \n    \n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_hue(image, 0.08)\n    image = tf.image.random_saturation(image, 0.6, 1.6)\n    image = tf.image.random_brightness(image, 0.05)\n    image = tf.image.random_contrast(image, 0.7, 1.3)\n    image = zoom(image)\n    image = rotate(image)\n    return image, label\n\nREPEAT_DATA_AUGMENT = 12\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES)\n    dataset = dataset.repeat(REPEAT_DATA_AUGMENT)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\n# Learning Rate Schedule for Fine Tuning #\ndef exponential_lr(epoch,\n                   start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005,\n                   rampup_epochs = 5, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        # constant max_lr during sustain_epochs\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        # exponential decay towards min_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\n\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES) * REPEAT_DATA_AUGMENT\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint('Dataset: {} training images, {} validation images, {} test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:06:59.963403Z","iopub.execute_input":"2022-03-10T21:06:59.963706Z","iopub.status.idle":"2022-03-10T21:06:59.987643Z","shell.execute_reply.started":"2022-03-10T21:06:59.963672Z","shell.execute_reply":"2022-03-10T21:06:59.986976Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Dataset: 114912 training images, 3177 validation images, 3712 test images\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n## Get Datasets Ready for Training <a name=\"datasets\">","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\nds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()\n\nprint(\"Training:\", ds_train)\nprint (\"Validation:\", ds_valid)\nprint(\"Test:\", ds_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:07:04.094466Z","iopub.execute_input":"2022-03-10T21:07:04.094953Z","iopub.status.idle":"2022-03-10T21:07:04.569892Z","shell.execute_reply.started":"2022-03-10T21:07:04.094901Z","shell.execute_reply":"2022-03-10T21:07:04.569157Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Training: <PrefetchDataset shapes: ((None, 224, 224, 3), (None,)), types: (tf.float32, tf.int32)>\nValidation: <PrefetchDataset shapes: ((None, 224, 224, 3), (None,)), types: (tf.float32, tf.int32)>\nTest: <PrefetchDataset shapes: ((None, 224, 224, 3), (None,)), types: (tf.float32, tf.string)>\n","output_type":"stream"}]},{"cell_type":"code","source":"print(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:07:04.738767Z","iopub.execute_input":"2022-03-10T21:07:04.739060Z","iopub.status.idle":"2022-03-10T21:07:04.743630Z","shell.execute_reply.started":"2022-03-10T21:07:04.739029Z","shell.execute_reply":"2022-03-10T21:07:04.743004Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"128\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Define Models <a name=\"models\">","metadata":{}},{"cell_type":"markdown","source":"### VGG <a name=\"vgg\">","metadata":{}},{"cell_type":"code","source":"\n# Define training epochs\nEPOCHS = 30\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nwith strategy.scope():\n    pretrained_vgg_model = tf.keras.applications.vgg16.VGG16(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    for layer in pretrained_vgg_model.layers:\n        if layer.name == 'block14_sepconv1' or layer.name == 'block14_sepconv2':\n           layer.trainable = True\n        else:\n            layer.trainable = False\n    \n    vgg_model = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_vgg_model,\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(500, activation='relu'),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:07:06.753100Z","iopub.execute_input":"2022-03-10T21:07:06.753371Z","iopub.status.idle":"2022-03-10T21:07:08.132074Z","shell.execute_reply.started":"2022-03-10T21:07:06.753344Z","shell.execute_reply":"2022-03-10T21:07:08.131065Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"pretrained_vgg_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:07:09.138397Z","iopub.execute_input":"2022-03-10T21:07:09.138697Z","iopub.status.idle":"2022-03-10T21:07:09.153589Z","shell.execute_reply.started":"2022-03-10T21:07:09.138667Z","shell.execute_reply":"2022-03-10T21:07:09.152381Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Model: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 0\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras import optimizers\n\noptimizer = optimizers.Adam(lr=0.01)\n\nvgg_model.compile(\n    optimizer=optimizer,\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nvgg_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:07:10.272432Z","iopub.execute_input":"2022-03-10T21:07:10.273343Z","iopub.status.idle":"2022-03-10T21:07:10.322372Z","shell.execute_reply.started":"2022-03-10T21:07:10.273303Z","shell.execute_reply":"2022-03-10T21:07:10.321482Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg16 (Functional)           (None, 7, 7, 512)         14714688  \n_________________________________________________________________\nglobal_average_pooling2d_2 ( (None, 512)               0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               256500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 104)               52104     \n=================================================================\nTotal params: 15,023,292\nTrainable params: 308,604\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n#from tensorflow.keras.callbacks import EarlyStopping\n\n#early_stopping = EarlyStopping(patience=3, verbose=1,restore_best_weights=True)\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\nvgg_history = vgg_model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH, \n    callbacks=[lr_callback]\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:07:12.559541Z","iopub.execute_input":"2022-03-10T21:07:12.559824Z","iopub.status.idle":"2022-03-10T21:37:50.923405Z","shell.execute_reply.started":"2022-03-10T21:07:12.559796Z","shell.execute_reply":"2022-03-10T21:37:50.922371Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 1/30\n\nEpoch 00001: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n897/897 [==============================] - 79s 76ms/step - loss: 2.7828 - sparse_categorical_accuracy: 0.3195 - val_loss: 1.8090 - val_sparse_categorical_accuracy: 0.5184\nEpoch 2/30\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 0.008009999821186066.\n  1/897 [..............................] - ETA: 1:08 - loss: 1.8523 - sparse_categorical_accuracy: 0.4609","output_type":"stream"},{"name":"stderr","text":"2022-03-10 21:08:31.444073: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 30188, Output num: 1\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1646946511.443981839\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 30188, Output num: 1\",\"grpc_status\":3}\n","output_type":"stream"},{"name":"stdout","text":"897/897 [==============================] - 60s 66ms/step - loss: 1.9256 - sparse_categorical_accuracy: 0.4856 - val_loss: 1.6235 - val_sparse_categorical_accuracy: 0.5710\nEpoch 3/30\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.004825999994277954.\n897/897 [==============================] - 61s 68ms/step - loss: 1.7324 - sparse_categorical_accuracy: 0.5283 - val_loss: 1.4942 - val_sparse_categorical_accuracy: 0.6009\nEpoch 4/30\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.0019603999841213225.\n897/897 [==============================] - 60s 66ms/step - loss: 1.6042 - sparse_categorical_accuracy: 0.5573 - val_loss: 1.4157 - val_sparse_categorical_accuracy: 0.6302\nEpoch 5/30\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.0004320800052583216.\n897/897 [==============================] - ETA: 0s - loss: 1.5286 - sparse_categorical_accuracy: 0.5764","output_type":"stream"},{"name":"stderr","text":"2022-03-10 21:12:30.181449: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 22359, Output num: 1\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1646946750.181162651\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 22359, Output num: 1\",\"grpc_status\":3}\n","output_type":"stream"},{"name":"stdout","text":"897/897 [==============================] - 60s 66ms/step - loss: 1.5286 - sparse_categorical_accuracy: 0.5764 - val_loss: 1.3955 - val_sparse_categorical_accuracy: 0.6431\nEpoch 6/30\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n897/897 [==============================] - 59s 66ms/step - loss: 1.4931 - sparse_categorical_accuracy: 0.5844 - val_loss: 1.3872 - val_sparse_categorical_accuracy: 0.6412\nEpoch 7/30\n\nEpoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n897/897 [==============================] - 59s 65ms/step - loss: 1.4918 - sparse_categorical_accuracy: 0.5890 - val_loss: 1.3853 - val_sparse_categorical_accuracy: 0.6387\nEpoch 8/30\n\nEpoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 1.4948 - sparse_categorical_accuracy: 0.5863 - val_loss: 1.3844 - val_sparse_categorical_accuracy: 0.6405\nEpoch 9/30\n\nEpoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 1.4889 - sparse_categorical_accuracy: 0.5861 - val_loss: 1.3842 - val_sparse_categorical_accuracy: 0.6418\nEpoch 10/30\n\nEpoch 00010: LearningRateScheduler reducing learning rate to 2.6384000000000004e-05.\n897/897 [==============================] - 59s 65ms/step - loss: 1.4800 - sparse_categorical_accuracy: 0.5869 - val_loss: 1.3839 - val_sparse_categorical_accuracy: 0.6396\nEpoch 11/30\n\nEpoch 00011: LearningRateScheduler reducing learning rate to 2.3107200000000005e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 1.4970 - sparse_categorical_accuracy: 0.5825 - val_loss: 1.3827 - val_sparse_categorical_accuracy: 0.6421\nEpoch 12/30\n\nEpoch 00012: LearningRateScheduler reducing learning rate to 2.0485760000000004e-05.\n897/897 [==============================] - 68s 76ms/step - loss: 1.4922 - sparse_categorical_accuracy: 0.5879 - val_loss: 1.3822 - val_sparse_categorical_accuracy: 0.6415\nEpoch 13/30\n\nEpoch 00013: LearningRateScheduler reducing learning rate to 1.8388608000000004e-05.\n897/897 [==============================] - 58s 64ms/step - loss: 1.4872 - sparse_categorical_accuracy: 0.5833 - val_loss: 1.3828 - val_sparse_categorical_accuracy: 0.6440\nEpoch 14/30\n\nEpoch 00014: LearningRateScheduler reducing learning rate to 1.6710886400000004e-05.\n897/897 [==============================] - 59s 66ms/step - loss: 1.4871 - sparse_categorical_accuracy: 0.5864 - val_loss: 1.3819 - val_sparse_categorical_accuracy: 0.6427\nEpoch 15/30\n\nEpoch 00015: LearningRateScheduler reducing learning rate to 1.5368709120000003e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 1.4852 - sparse_categorical_accuracy: 0.5875 - val_loss: 1.3816 - val_sparse_categorical_accuracy: 0.6431\nEpoch 16/30\n\nEpoch 00016: LearningRateScheduler reducing learning rate to 1.4294967296000005e-05.\n897/897 [==============================] - 59s 65ms/step - loss: 1.4947 - sparse_categorical_accuracy: 0.5849 - val_loss: 1.3823 - val_sparse_categorical_accuracy: 0.6424\nEpoch 17/30\n\nEpoch 00017: LearningRateScheduler reducing learning rate to 1.3435973836800004e-05.\n897/897 [==============================] - 59s 65ms/step - loss: 1.4875 - sparse_categorical_accuracy: 0.5851 - val_loss: 1.3818 - val_sparse_categorical_accuracy: 0.6440\nEpoch 18/30\n\nEpoch 00018: LearningRateScheduler reducing learning rate to 1.2748779069440003e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 1.4896 - sparse_categorical_accuracy: 0.5875 - val_loss: 1.3816 - val_sparse_categorical_accuracy: 0.6427\nEpoch 19/30\n\nEpoch 00019: LearningRateScheduler reducing learning rate to 1.2199023255552003e-05.\n897/897 [==============================] - 58s 64ms/step - loss: 1.4795 - sparse_categorical_accuracy: 0.5885 - val_loss: 1.3818 - val_sparse_categorical_accuracy: 0.6434\nEpoch 20/30\n\nEpoch 00020: LearningRateScheduler reducing learning rate to 1.1759218604441602e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 1.4862 - sparse_categorical_accuracy: 0.5860 - val_loss: 1.3814 - val_sparse_categorical_accuracy: 0.6449\nEpoch 21/30\n\nEpoch 00021: LearningRateScheduler reducing learning rate to 1.1407374883553282e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 1.4865 - sparse_categorical_accuracy: 0.5861 - val_loss: 1.3807 - val_sparse_categorical_accuracy: 0.6443\nEpoch 22/30\n\nEpoch 00022: LearningRateScheduler reducing learning rate to 1.1125899906842627e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 1.4829 - sparse_categorical_accuracy: 0.5857 - val_loss: 1.3810 - val_sparse_categorical_accuracy: 0.6443\nEpoch 23/30\n\nEpoch 00023: LearningRateScheduler reducing learning rate to 1.0900719925474101e-05.\n897/897 [==============================] - 70s 78ms/step - loss: 1.4861 - sparse_categorical_accuracy: 0.5880 - val_loss: 1.3807 - val_sparse_categorical_accuracy: 0.6434\nEpoch 24/30\n\nEpoch 00024: LearningRateScheduler reducing learning rate to 1.0720575940379282e-05.\n897/897 [==============================] - 86s 96ms/step - loss: 1.4752 - sparse_categorical_accuracy: 0.5884 - val_loss: 1.3807 - val_sparse_categorical_accuracy: 0.6440\nEpoch 25/30\n\nEpoch 00025: LearningRateScheduler reducing learning rate to 1.0576460752303425e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 1.4916 - sparse_categorical_accuracy: 0.5863 - val_loss: 1.3805 - val_sparse_categorical_accuracy: 0.6434\nEpoch 26/30\n\nEpoch 00026: LearningRateScheduler reducing learning rate to 1.046116860184274e-05.\n897/897 [==============================] - 59s 65ms/step - loss: 1.4755 - sparse_categorical_accuracy: 0.5908 - val_loss: 1.3808 - val_sparse_categorical_accuracy: 0.6443\nEpoch 27/30\n\nEpoch 00027: LearningRateScheduler reducing learning rate to 1.0368934881474192e-05.\n897/897 [==============================] - 67s 75ms/step - loss: 1.4909 - sparse_categorical_accuracy: 0.5874 - val_loss: 1.3796 - val_sparse_categorical_accuracy: 0.6449\nEpoch 28/30\n\nEpoch 00028: LearningRateScheduler reducing learning rate to 1.0295147905179355e-05.\n897/897 [==============================] - 59s 66ms/step - loss: 1.4703 - sparse_categorical_accuracy: 0.5882 - val_loss: 1.3797 - val_sparse_categorical_accuracy: 0.6446\nEpoch 29/30\n\nEpoch 00029: LearningRateScheduler reducing learning rate to 1.0236118324143484e-05.\n897/897 [==============================] - 59s 66ms/step - loss: 1.4817 - sparse_categorical_accuracy: 0.5885 - val_loss: 1.3795 - val_sparse_categorical_accuracy: 0.6443\nEpoch 30/30\n\nEpoch 00030: LearningRateScheduler reducing learning rate to 1.0188894659314786e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 1.4838 - sparse_categorical_accuracy: 0.5870 - val_loss: 1.3792 - val_sparse_categorical_accuracy: 0.6449\n","output_type":"stream"}]},{"cell_type":"code","source":"save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\nvgg_model.save('./vggmodel', options=save_locally)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:39:26.238890Z","iopub.execute_input":"2022-03-10T21:39:26.239651Z","iopub.status.idle":"2022-03-10T21:39:30.063240Z","shell.execute_reply.started":"2022-03-10T21:39:26.239606Z","shell.execute_reply":"2022-03-10T21:39:30.062370Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"2022-03-10 21:39:27.108941: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n### Resnet50 <a name=\"resnet\">","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    pretrained_resnet_model = tf.keras.applications.resnet50.ResNet50(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    for layer in pretrained_resnet_model.layers:\n        if layer.name == 'block14_sepconv1' or layer.name == 'block14_sepconv2':\n           layer.trainable = True\n        else:\n            layer.trainable = False\n    \n    resnet_model = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_resnet_model,\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(500, activation='relu'),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:40:36.049364Z","iopub.execute_input":"2022-03-10T21:40:36.050176Z","iopub.status.idle":"2022-03-10T21:40:46.790428Z","shell.execute_reply.started":"2022-03-10T21:40:36.050132Z","shell.execute_reply":"2022-03-10T21:40:46.789608Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"pretrained_resnet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:40:50.581715Z","iopub.execute_input":"2022-03-10T21:40:50.582674Z","iopub.status.idle":"2022-03-10T21:40:50.661620Z","shell.execute_reply.started":"2022-03-10T21:40:50.582623Z","shell.execute_reply":"2022-03-10T21:40:50.660694Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Model: \"resnet50\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\nconv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_4[0][0]                    \n__________________________________________________________________________________________________\nconv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n__________________________________________________________________________________________________\nconv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n__________________________________________________________________________________________________\npool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n__________________________________________________________________________________________________\npool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n                                                                 conv2_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n                                                                 conv2_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n                                                                 conv2_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n                                                                 conv3_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n                                                                 conv3_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n                                                                 conv3_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n                                                                 conv3_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n                                                                 conv4_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n                                                                 conv4_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n                                                                 conv4_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n                                                                 conv4_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n                                                                 conv4_block5_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n                                                                 conv4_block6_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n                                                                 conv5_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n                                                                 conv5_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n                                                                 conv5_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n==================================================================================================\nTotal params: 23,587,712\nTrainable params: 0\nNon-trainable params: 23,587,712\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"resnet_model.compile(\n    optimizer=optimizer,\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nresnet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:40:56.648073Z","iopub.execute_input":"2022-03-10T21:40:56.648602Z","iopub.status.idle":"2022-03-10T21:40:56.705082Z","shell.execute_reply.started":"2022-03-10T21:40:56.648550Z","shell.execute_reply":"2022-03-10T21:40:56.704131Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n_________________________________________________________________\nglobal_average_pooling2d_3 ( (None, 2048)              0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 500)               1024500   \n_________________________________________________________________\ndense_7 (Dense)              (None, 104)               52104     \n=================================================================\nTotal params: 24,664,316\nTrainable params: 1,076,604\nNon-trainable params: 23,587,712\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\nresnet_history = resnet_model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback]\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:40:59.813542Z","iopub.execute_input":"2022-03-10T21:40:59.813838Z","iopub.status.idle":"2022-03-10T22:11:58.469669Z","shell.execute_reply.started":"2022-03-10T21:40:59.813809Z","shell.execute_reply":"2022-03-10T22:11:58.468690Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch 1/30\n\nEpoch 00001: LearningRateScheduler reducing learning rate to 1.0188894520979375e-05.\n897/897 [==============================] - 81s 77ms/step - loss: 4.3345 - sparse_categorical_accuracy: 0.0520 - val_loss: 4.1389 - val_sparse_categorical_accuracy: 0.0630\nEpoch 2/30\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 1.81511156167835e-05.\n  1/897 [..............................] - ETA: 1:05 - loss: 4.1813 - sparse_categorical_accuracy: 0.0703","output_type":"stream"},{"name":"stderr","text":"2022-03-10 21:42:21.233204: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 203757, Output num: 1\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1646948541.233081490\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 203757, Output num: 1\",\"grpc_status\":3}\n","output_type":"stream"},{"name":"stdout","text":"897/897 [==============================] - 61s 68ms/step - loss: 4.1587 - sparse_categorical_accuracy: 0.0707 - val_loss: 4.1135 - val_sparse_categorical_accuracy: 0.0730\nEpoch 3/30\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 3.089066900021862e-05.\n897/897 [==============================] - 61s 68ms/step - loss: 4.1241 - sparse_categorical_accuracy: 0.0777 - val_loss: 4.0853 - val_sparse_categorical_accuracy: 0.0796\nEpoch 4/30\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 4.2356266961432993e-05.\n897/897 [==============================] - 60s 67ms/step - loss: 4.0952 - sparse_categorical_accuracy: 0.0826 - val_loss: 4.0541 - val_sparse_categorical_accuracy: 0.0897\nEpoch 5/30\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 4.8471253386233007e-05.\n897/897 [==============================] - 60s 67ms/step - loss: 4.0640 - sparse_categorical_accuracy: 0.0881 - val_loss: 4.0262 - val_sparse_categorical_accuracy: 0.0847\nEpoch 6/30\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n897/897 [==============================] - 66s 74ms/step - loss: 4.0410 - sparse_categorical_accuracy: 0.0907 - val_loss: 4.0038 - val_sparse_categorical_accuracy: 0.0844\nEpoch 7/30\n\nEpoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n897/897 [==============================] - 59s 65ms/step - loss: 4.0208 - sparse_categorical_accuracy: 0.0926 - val_loss: 3.9843 - val_sparse_categorical_accuracy: 0.1014\nEpoch 8/30\n\nEpoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n897/897 [==============================] - 60s 67ms/step - loss: 3.9996 - sparse_categorical_accuracy: 0.0956 - val_loss: 3.9727 - val_sparse_categorical_accuracy: 0.0963\nEpoch 9/30\n\nEpoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 3.9875 - sparse_categorical_accuracy: 0.0967 - val_loss: 3.9606 - val_sparse_categorical_accuracy: 0.0982\nEpoch 10/30\n\nEpoch 00010: LearningRateScheduler reducing learning rate to 2.6384000000000004e-05.\n897/897 [==============================] - 67s 74ms/step - loss: 3.9755 - sparse_categorical_accuracy: 0.0970 - val_loss: 3.9505 - val_sparse_categorical_accuracy: 0.1029\nEpoch 11/30\n\nEpoch 00011: LearningRateScheduler reducing learning rate to 2.3107200000000005e-05.\n897/897 [==============================] - 59s 66ms/step - loss: 3.9671 - sparse_categorical_accuracy: 0.0999 - val_loss: 3.9451 - val_sparse_categorical_accuracy: 0.0966\nEpoch 12/30\n\nEpoch 00012: LearningRateScheduler reducing learning rate to 2.0485760000000004e-05.\n897/897 [==============================] - 58s 64ms/step - loss: 3.9587 - sparse_categorical_accuracy: 0.1003 - val_loss: 3.9377 - val_sparse_categorical_accuracy: 0.1039\nEpoch 13/30\n\nEpoch 00013: LearningRateScheduler reducing learning rate to 1.8388608000000004e-05.\n897/897 [==============================] - 59s 66ms/step - loss: 3.9518 - sparse_categorical_accuracy: 0.1024 - val_loss: 3.9317 - val_sparse_categorical_accuracy: 0.1032\nEpoch 14/30\n\nEpoch 00014: LearningRateScheduler reducing learning rate to 1.6710886400000004e-05.\n897/897 [==============================] - 73s 81ms/step - loss: 3.9469 - sparse_categorical_accuracy: 0.1019 - val_loss: 3.9249 - val_sparse_categorical_accuracy: 0.1105\nEpoch 15/30\n\nEpoch 00015: LearningRateScheduler reducing learning rate to 1.5368709120000003e-05.\n897/897 [==============================] - 59s 66ms/step - loss: 3.9421 - sparse_categorical_accuracy: 0.1042 - val_loss: 3.9203 - val_sparse_categorical_accuracy: 0.1083\nEpoch 16/30\n\nEpoch 00016: LearningRateScheduler reducing learning rate to 1.4294967296000005e-05.\n897/897 [==============================] - 62s 69ms/step - loss: 3.9334 - sparse_categorical_accuracy: 0.1040 - val_loss: 3.9171 - val_sparse_categorical_accuracy: 0.1042\nEpoch 17/30\n\nEpoch 00017: LearningRateScheduler reducing learning rate to 1.3435973836800004e-05.\n897/897 [==============================] - 59s 65ms/step - loss: 3.9309 - sparse_categorical_accuracy: 0.1048 - val_loss: 3.9120 - val_sparse_categorical_accuracy: 0.1061\nEpoch 18/30\n\nEpoch 00018: LearningRateScheduler reducing learning rate to 1.2748779069440003e-05.\n897/897 [==============================] - 63s 70ms/step - loss: 3.9281 - sparse_categorical_accuracy: 0.1062 - val_loss: 3.9089 - val_sparse_categorical_accuracy: 0.1076\nEpoch 19/30\n\nEpoch 00019: LearningRateScheduler reducing learning rate to 1.2199023255552003e-05.\n897/897 [==============================] - 59s 65ms/step - loss: 3.9280 - sparse_categorical_accuracy: 0.1062 - val_loss: 3.9063 - val_sparse_categorical_accuracy: 0.1095\nEpoch 20/30\n\nEpoch 00020: LearningRateScheduler reducing learning rate to 1.1759218604441602e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 3.9198 - sparse_categorical_accuracy: 0.1071 - val_loss: 3.9017 - val_sparse_categorical_accuracy: 0.1095\nEpoch 21/30\n\nEpoch 00021: LearningRateScheduler reducing learning rate to 1.1407374883553282e-05.\n897/897 [==============================] - 59s 66ms/step - loss: 3.9201 - sparse_categorical_accuracy: 0.1066 - val_loss: 3.8980 - val_sparse_categorical_accuracy: 0.1095\nEpoch 22/30\n\nEpoch 00022: LearningRateScheduler reducing learning rate to 1.1125899906842627e-05.\n897/897 [==============================] - 62s 69ms/step - loss: 3.9197 - sparse_categorical_accuracy: 0.1051 - val_loss: 3.8963 - val_sparse_categorical_accuracy: 0.1067\nEpoch 23/30\n\nEpoch 00023: LearningRateScheduler reducing learning rate to 1.0900719925474101e-05.\n897/897 [==============================] - 58s 65ms/step - loss: 3.9182 - sparse_categorical_accuracy: 0.1063 - val_loss: 3.8925 - val_sparse_categorical_accuracy: 0.1108\nEpoch 24/30\n\nEpoch 00024: LearningRateScheduler reducing learning rate to 1.0720575940379282e-05.\n897/897 [==============================] - 64s 71ms/step - loss: 3.9043 - sparse_categorical_accuracy: 0.1085 - val_loss: 3.8894 - val_sparse_categorical_accuracy: 0.1086\nEpoch 25/30\n\nEpoch 00025: LearningRateScheduler reducing learning rate to 1.0576460752303425e-05.\n897/897 [==============================] - 59s 66ms/step - loss: 3.9062 - sparse_categorical_accuracy: 0.1107 - val_loss: 3.8859 - val_sparse_categorical_accuracy: 0.1121\nEpoch 26/30\n\nEpoch 00026: LearningRateScheduler reducing learning rate to 1.046116860184274e-05.\n897/897 [==============================] - 63s 71ms/step - loss: 3.9056 - sparse_categorical_accuracy: 0.1082 - val_loss: 3.8834 - val_sparse_categorical_accuracy: 0.1117\nEpoch 27/30\n\nEpoch 00027: LearningRateScheduler reducing learning rate to 1.0368934881474192e-05.\n897/897 [==============================] - 64s 72ms/step - loss: 3.9025 - sparse_categorical_accuracy: 0.1092 - val_loss: 3.8793 - val_sparse_categorical_accuracy: 0.1121\nEpoch 28/30\n\nEpoch 00028: LearningRateScheduler reducing learning rate to 1.0295147905179355e-05.\n897/897 [==============================] - 59s 66ms/step - loss: 3.8972 - sparse_categorical_accuracy: 0.1096 - val_loss: 3.8772 - val_sparse_categorical_accuracy: 0.1121\nEpoch 29/30\n\nEpoch 00029: LearningRateScheduler reducing learning rate to 1.0236118324143484e-05.\n897/897 [==============================] - 68s 76ms/step - loss: 3.8951 - sparse_categorical_accuracy: 0.1099 - val_loss: 3.8760 - val_sparse_categorical_accuracy: 0.1146\nEpoch 30/30\n\nEpoch 00030: LearningRateScheduler reducing learning rate to 1.0188894659314786e-05.\n897/897 [==============================] - 59s 66ms/step - loss: 3.8957 - sparse_categorical_accuracy: 0.1102 - val_loss: 3.8719 - val_sparse_categorical_accuracy: 0.1143\n","output_type":"stream"}]},{"cell_type":"code","source":"save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\nresnet_model.save('./resnetmodel', options=save_locally)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T22:13:24.833721Z","iopub.execute_input":"2022-03-10T22:13:24.834054Z","iopub.status.idle":"2022-03-10T22:14:00.596092Z","shell.execute_reply.started":"2022-03-10T22:13:24.834022Z","shell.execute_reply":"2022-03-10T22:14:00.594998Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"\n### InceptionNet V3 <a name=\"inception\">","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    pretrained_inception_model = tf.keras.applications.inception_v3.InceptionV3(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    for layer in pretrained_inception_model.layers:\n        if layer.name == 'block14_sepconv1' or layer.name == 'block14_sepconv2':\n           layer.trainable = True\n        else:\n            layer.trainable = False\n    \n    inception_model = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_inception_model,\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(500, activation='relu'),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T16:33:15.615086Z","iopub.execute_input":"2022-02-25T16:33:15.61543Z","iopub.status.idle":"2022-02-25T16:33:34.181488Z","shell.execute_reply.started":"2022-02-25T16:33:15.6154Z","shell.execute_reply":"2022-02-25T16:33:34.180513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_inception_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T16:33:34.182752Z","iopub.execute_input":"2022-02-25T16:33:34.182979Z","iopub.status.idle":"2022-02-25T16:33:34.325514Z","shell.execute_reply.started":"2022-02-25T16:33:34.182953Z","shell.execute_reply":"2022-02-25T16:33:34.324443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception_model.compile(\n    optimizer=optimizer,\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\ninception_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T16:33:34.327057Z","iopub.execute_input":"2022-02-25T16:33:34.328077Z","iopub.status.idle":"2022-02-25T16:33:34.483047Z","shell.execute_reply.started":"2022-02-25T16:33:34.328038Z","shell.execute_reply":"2022-02-25T16:33:34.481999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception_history = inception_model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback]\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T16:33:34.484585Z","iopub.execute_input":"2022-02-25T16:33:34.48491Z","iopub.status.idle":"2022-02-25T19:16:33.072605Z","shell.execute_reply.started":"2022-02-25T16:33:34.484869Z","shell.execute_reply":"2022-02-25T19:16:33.071506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\ninception_model.save('./inceptionmodel', options=save_locally)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:17:48.616685Z","iopub.execute_input":"2022-02-25T19:17:48.61746Z","iopub.status.idle":"2022-02-25T19:18:47.674174Z","shell.execute_reply.started":"2022-02-25T19:17:48.617414Z","shell.execute_reply":"2022-02-25T19:18:47.673387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate Models <a name=\"evaluate\">","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\ndef display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(15,15))\n    ax = plt.gca()\n    ax.matshow(cmat, cmap='Reds')\n    ax.set_xticks(range(len(CLASSES)))\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n    ax.set_yticks(range(len(CLASSES)))\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall)\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n    plt.show()\n\ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:20:32.475288Z","iopub.execute_input":"2022-02-25T19:20:32.475734Z","iopub.status.idle":"2022-02-25T19:20:33.449458Z","shell.execute_reply.started":"2022-02-25T19:20:32.4757Z","shell.execute_reply":"2022-02-25T19:20:33.448578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Curves <a name=\"curves\">","metadata":{}},{"cell_type":"code","source":"#Training Curves for the vgg model\ndisplay_training_curves(\n    vgg_history.history['loss'],\n    vgg_history.history['val_loss'],\n    'vgg model loss',\n    211)\n\ndisplay_training_curves(\n    vgg_history.history['sparse_categorical_accuracy'],\n    vgg_history.history['val_sparse_categorical_accuracy'],\n    'vgg model accuracy',\n    212)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:20:41.489762Z","iopub.execute_input":"2022-02-25T19:20:41.490133Z","iopub.status.idle":"2022-02-25T19:20:42.078424Z","shell.execute_reply.started":"2022-02-25T19:20:41.490097Z","shell.execute_reply":"2022-02-25T19:20:42.077421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training Curves for the resnet 50 model\ndisplay_training_curves(\n    resnet_history.history['loss'],\n    resnet_history.history['val_loss'],\n    'resnet model loss',\n    211)\n\ndisplay_training_curves(\n    vgg_history.history['sparse_categorical_accuracy'],\n    vgg_history.history['val_sparse_categorical_accuracy'],\n    'resnet model accuracy',\n    212)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:20:52.606596Z","iopub.execute_input":"2022-02-25T19:20:52.607381Z","iopub.status.idle":"2022-02-25T19:20:53.17101Z","shell.execute_reply.started":"2022-02-25T19:20:52.607331Z","shell.execute_reply":"2022-02-25T19:20:53.170133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training Curves for the inception V3 model\ndisplay_training_curves(\n    inception_history.history['loss'],\n    inception_history.history['val_loss'],\n    'inception V3 model loss',\n    211)\n\ndisplay_training_curves(\n    inception_history.history['sparse_categorical_accuracy'],\n    inception_history.history['val_sparse_categorical_accuracy'],\n    'inception V3 model accuracy',\n    212)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:21:00.411895Z","iopub.execute_input":"2022-02-25T19:21:00.412568Z","iopub.status.idle":"2022-02-25T19:21:00.899225Z","shell.execute_reply.started":"2022-02-25T19:21:00.412522Z","shell.execute_reply":"2022-02-25T19:21:00.898258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### Confusion Matrix <a name=\"matrix\">","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#### VGG <a name=\"vggmatrix\">","metadata":{}},{"cell_type":"code","source":"cmdataset = get_test_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_TEST_IMAGES))).numpy()\nvgg_cm_probabilities = vgg_model.predict(images_ds)\nvgg_cm_predictions = np.argmax(vgg_cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\nvgg_cmat = confusion_matrix(\n    cm_correct_labels,\n    vgg_cm_predictions,\n    labels=labels\n)\nvgg_cmat = (vgg_cmat.T / vgg_cmat.sum(axis=1)).T # normalize","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_f1_score = f1_score(\n    cm_correct_labels,\n    vgg_cm_predictions,\n    labels=labels,\n    average='macro',\n)\nvgg_precision = precision_score(\n    cm_correct_labels,\n    vgg_cm_predictions,\n    labels=labels,\n    average='macro',\n)\nvgg_recall = recall_score(\n    cm_correct_labels,\n    vgg_cm_predictions,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(vgg_cmat, vgg_score, vgg_precision, vgg_recall)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Resnet50 <a name=\"resnetmatrix\">","metadata":{}},{"cell_type":"code","source":"cmdataset = get_test_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_TEST_IMAGES))).numpy()\nresnet_cm_probabilities = resnet_model.predict(images_ds)\nresnet_cm_predictions = np.argmax(resnet_cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\nresnet_cmat = confusion_matrix(\n    cm_correct_labels,\n    resnet_cm_predictions,\n    labels=labels,\n)\nresnet_cmat = (resnet_cmat.T / resnet_cmat.sum(axis=1)).T # normalize","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_f1_score = f1_score(\n    cm_correct_labels,\n    resnet_cm_predictions,\n    labels=labels,\n    average='macro',\n)\nresnet_precision = precision_score(\n    cm_correct_labels,\n    resnet_cm_predictions,\n    labels=labels,\n    average='macro',\n)\nresnet_recall = recall_score(\n    cm_correct_labels,\n    resnet_cm_predictions,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(resnet_cmat, resnet_score, resnet_precision, resnet_recall)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### InceptionNet V3 <a name=\"inceptionmatrix\">","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}