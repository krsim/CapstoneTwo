{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac732a2",
   "metadata": {
    "papermill": {
     "duration": 0.025846,
     "end_time": "2022-02-25T12:14:41.348333",
     "exception": false,
     "start_time": "2022-02-25T12:14:41.322487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models\n",
    "\n",
    "In this notebook, the data is uploaded from Kaggle dataset and stored in a Google Coud Storage bucket to be used with TPUs. The data itself is in a tfrec format for convenient distribution to the TPU cores.\n",
    "\n",
    "The final layers of three pretrained networks are trained on the data and the results are compared in the next notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5dbdf",
   "metadata": {
    "papermill": {
     "duration": 0.025455,
     "end_time": "2022-02-25T12:14:41.401879",
     "exception": false,
     "start_time": "2022-02-25T12:14:41.376424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e56a419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:41.457838Z",
     "iopub.status.busy": "2022-02-25T12:14:41.456650Z",
     "iopub.status.idle": "2022-02-25T12:14:46.769834Z",
     "shell.execute_reply": "2022-02-25T12:14:46.768829Z",
     "shell.execute_reply.started": "2022-02-25T00:56:58.408084Z"
    },
    "papermill": {
     "duration": 5.341578,
     "end_time": "2022-02-25T12:14:46.770038",
     "exception": false,
     "start_time": "2022-02-25T12:14:41.428460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 12:14:42.056310: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-02-25 12:14:42.056445: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import math, re, os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233cf41",
   "metadata": {
    "papermill": {
     "duration": 0.02507,
     "end_time": "2022-02-25T12:14:46.821069",
     "exception": false,
     "start_time": "2022-02-25T12:14:46.795999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Distribution Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8434834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:46.883296Z",
     "iopub.status.busy": "2022-02-25T12:14:46.882553Z",
     "iopub.status.idle": "2022-02-25T12:14:52.759358Z",
     "shell.execute_reply": "2022-02-25T12:14:52.759888Z",
     "shell.execute_reply.started": "2022-02-25T00:57:08.392774Z"
    },
    "papermill": {
     "duration": 5.91311,
     "end_time": "2022-02-25T12:14:52.760096",
     "exception": false,
     "start_time": "2022-02-25T12:14:46.846986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 12:14:46.885452: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-25 12:14:46.888569: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-02-25 12:14:46.888607: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-25 12:14:46.888633: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (329d78ec7837): /proc/driver/nvidia/version does not exist\n",
      "2022-02-25 12:14:46.891599: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-25 12:14:46.893319: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-25 12:14:46.923220: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-02-25 12:14:46.923286: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n",
      "2022-02-25 12:14:46.947038: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-02-25 12:14:46.947111: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n",
      "2022-02-25 12:14:46.948738: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "# Detect TPU, return distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print(\"Running on TPU \", tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "    \n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    \n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b981d4",
   "metadata": {
    "papermill": {
     "duration": 0.025895,
     "end_time": "2022-02-25T12:14:52.812405",
     "exception": false,
     "start_time": "2022-02-25T12:14:52.786510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57d4d58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:52.867866Z",
     "iopub.status.busy": "2022-02-25T12:14:52.867245Z",
     "iopub.status.idle": "2022-02-25T12:14:53.380428Z",
     "shell.execute_reply": "2022-02-25T12:14:53.379713Z",
     "shell.execute_reply.started": "2022-02-25T00:57:21.277272Z"
    },
    "papermill": {
     "duration": 0.542037,
     "end_time": "2022-02-25T12:14:53.380582",
     "exception": false,
     "start_time": "2022-02-25T12:14:52.838545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://kds-b20d76a1b41f2ab9b562091a201f97414f08e23e6c1f4e376d0f0a23\n"
     ]
    }
   ],
   "source": [
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')\n",
    "print(GCS_DS_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b0ef7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:53.439176Z",
     "iopub.status.busy": "2022-02-25T12:14:53.438151Z",
     "iopub.status.idle": "2022-02-25T12:14:53.444925Z",
     "shell.execute_reply": "2022-02-25T12:14:53.444203Z",
     "shell.execute_reply.started": "2022-02-25T00:57:25.13947Z"
    },
    "papermill": {
     "duration": 0.036769,
     "end_time": "2022-02-25T12:14:53.445124",
     "exception": false,
     "start_time": "2022-02-25T12:14:53.408355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpu-getting-started\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dirs = os.listdir(\"../input\")\n",
    "\n",
    "for file in dirs:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100e75e",
   "metadata": {
    "papermill": {
     "duration": 0.026633,
     "end_time": "2022-02-25T12:14:53.499549",
     "exception": false,
     "start_time": "2022-02-25T12:14:53.472916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The Kaggle data is split into a labeled training set, a labeled validation set, and an unlabeled test set. The unlabeled set is used for competition submission and will not be used here. Instead, the validation set will be used as the test set and the training set will be split for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9127509e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:53.557268Z",
     "iopub.status.busy": "2022-02-25T12:14:53.556500Z",
     "iopub.status.idle": "2022-02-25T12:14:53.837207Z",
     "shell.execute_reply": "2022-02-25T12:14:53.836650Z",
     "shell.execute_reply.started": "2022-02-25T01:00:56.508947Z"
    },
    "papermill": {
     "duration": 0.310633,
     "end_time": "2022-02-25T12:14:53.837356",
     "exception": false,
     "start_time": "2022-02-25T12:14:53.526723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 12:14:53.579005: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-25 12:14:53.762749: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "IMAGE_SIZE = [331, 331]\n",
    "GCS_PATH =  GCS_DS_PATH + '/tfrecords-jpeg-331x331'\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "validation_split = 0.25\n",
    "data_files = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n",
    "split = len(data_files) - int(len(data_files) * validation_split)\n",
    "\n",
    "TRAINING_FILENAMES = data_files[:split]\n",
    "VALIDATION_FILENAMES = data_files[split:]\n",
    "TEST_FILENAMES =  tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n",
    "\n",
    "CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n",
    "           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n",
    "           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n",
    "           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n",
    "           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n",
    "           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n",
    "           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n",
    "           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n",
    "           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n",
    "           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n",
    "           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102\n",
    "\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['class'], tf.int32)\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
    "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    idnum = example['id']\n",
    "    return image, idnum # returns a dataset of image(s)\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae39d50a",
   "metadata": {
    "papermill": {
     "duration": 0.027261,
     "end_time": "2022-02-25T12:14:53.892369",
     "exception": false,
     "start_time": "2022-02-25T12:14:53.865108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Helper Functions\n",
    "\n",
    "Functios to augment and retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d216b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:53.950437Z",
     "iopub.status.busy": "2022-02-25T12:14:53.949761Z",
     "iopub.status.idle": "2022-02-25T12:14:53.978091Z",
     "shell.execute_reply": "2022-02-25T12:14:53.977047Z",
     "shell.execute_reply.started": "2022-02-25T01:02:02.917513Z"
    },
    "papermill": {
     "duration": 0.058223,
     "end_time": "2022-02-25T12:14:53.978346",
     "exception": false,
     "start_time": "2022-02-25T12:14:53.920123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 114912 training images, 3177 validation images, 3712 test images\n"
     ]
    }
   ],
   "source": [
    "def zoom(x: tf.Tensor) -> tf.Tensor:\n",
    "    #Zoom Augmentation\n",
    "    \n",
    "    scales = list(np.arange(0.8, 1.2, 0.02))\n",
    "    boxes = np.zeros((len(scales), 4))\n",
    "    \n",
    "    for i, scale in enumerate(scales):\n",
    "        x1 = y1 = 0.5 - (0.5 * scale)\n",
    "        x2 = y2 = 0.5 + (0.5 * scale)\n",
    "        boxes[i] = [x1, y1, x2, y2]\n",
    "        \n",
    "    def random_crop(img):\n",
    "        #Create different crops\n",
    "        crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=(331, 331) )\n",
    "        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
    "    \n",
    "    choice =  tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "    \n",
    "    #Applies 50% of the time\n",
    "    return tf.cond(choice < 0.5, lambda: x, lambda: random_crop(x))\n",
    "\n",
    "\n",
    "def rotate(x: tf.Tensor) -> tf.Tensor:\n",
    "    \n",
    "    image = tf.cond(tf.greater(tf.random.uniform([]), 0.5), lambda: tf.image.rot90(x), lambda: x)\n",
    "    return image\n",
    "\n",
    "def data_augment(image, label):\n",
    "    #Execute a series of random image augmentations \n",
    "    \n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_hue(image, 0.08)\n",
    "    image = tf.image.random_saturation(image, 0.6, 1.6)\n",
    "    image = tf.image.random_brightness(image, 0.05)\n",
    "    image = tf.image.random_contrast(image, 0.7, 1.3)\n",
    "    image = zoom(image)\n",
    "    image = rotate(image)\n",
    "    return image, label\n",
    "\n",
    "REPEAT_DATA_AUGMENT = 12\n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES)\n",
    "    dataset = dataset.repeat(REPEAT_DATA_AUGMENT)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(ordered=False):\n",
    "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(ordered=False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "# Learning Rate Schedule for Fine Tuning #\n",
    "def exponential_lr(epoch,\n",
    "                   start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005,\n",
    "                   rampup_epochs = 5, sustain_epochs = 0,\n",
    "                   exp_decay = 0.8):\n",
    "\n",
    "    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n",
    "        # linear increase from start to rampup_epochs\n",
    "        if epoch < rampup_epochs:\n",
    "            lr = ((max_lr - start_lr) /\n",
    "                  rampup_epochs * epoch + start_lr)\n",
    "        # constant max_lr during sustain_epochs\n",
    "        elif epoch < rampup_epochs + sustain_epochs:\n",
    "            lr = max_lr\n",
    "        # exponential decay towards min_lr\n",
    "        else:\n",
    "            lr = ((max_lr - min_lr) *\n",
    "                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n",
    "                  min_lr)\n",
    "        return lr\n",
    "    return lr(epoch,\n",
    "              start_lr,\n",
    "              min_lr,\n",
    "              max_lr,\n",
    "              rampup_epochs,\n",
    "              sustain_epochs,\n",
    "              exp_decay)\n",
    "\n",
    "\n",
    "\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES) * REPEAT_DATA_AUGMENT\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "print('Dataset: {} training images, {} validation images, {} test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004807e",
   "metadata": {
    "papermill": {
     "duration": 0.027014,
     "end_time": "2022-02-25T12:14:54.034176",
     "exception": false,
     "start_time": "2022-02-25T12:14:54.007162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Get Datasets Ready for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d408a55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:54.094210Z",
     "iopub.status.busy": "2022-02-25T12:14:54.093516Z",
     "iopub.status.idle": "2022-02-25T12:14:54.805060Z",
     "shell.execute_reply": "2022-02-25T12:14:54.804219Z",
     "shell.execute_reply.started": "2022-02-25T01:02:07.379902Z"
    },
    "papermill": {
     "duration": 0.742785,
     "end_time": "2022-02-25T12:14:54.805249",
     "exception": false,
     "start_time": "2022-02-25T12:14:54.062464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: <PrefetchDataset shapes: ((None, 331, 331, 3), (None,)), types: (tf.float32, tf.int32)>\n",
      "Validation: <PrefetchDataset shapes: ((None, 331, 331, 3), (None,)), types: (tf.float32, tf.int32)>\n",
      "Test: <PrefetchDataset shapes: ((None, 331, 331, 3), (None,)), types: (tf.float32, tf.string)>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "\n",
    "ds_train = get_training_dataset()\n",
    "ds_valid = get_validation_dataset()\n",
    "ds_test = get_test_dataset()\n",
    "\n",
    "print(\"Training:\", ds_train)\n",
    "print (\"Validation:\", ds_valid)\n",
    "print(\"Test:\", ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508c8fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:54.867488Z",
     "iopub.status.busy": "2022-02-25T12:14:54.866495Z",
     "iopub.status.idle": "2022-02-25T12:14:54.869722Z",
     "shell.execute_reply": "2022-02-25T12:14:54.870265Z",
     "shell.execute_reply.started": "2022-02-25T01:02:25.49288Z"
    },
    "papermill": {
     "duration": 0.036939,
     "end_time": "2022-02-25T12:14:54.870435",
     "exception": false,
     "start_time": "2022-02-25T12:14:54.833496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc88536",
   "metadata": {
    "papermill": {
     "duration": 0.028936,
     "end_time": "2022-02-25T12:14:54.927368",
     "exception": false,
     "start_time": "2022-02-25T12:14:54.898432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f0a48",
   "metadata": {
    "papermill": {
     "duration": 0.028145,
     "end_time": "2022-02-25T12:14:54.983723",
     "exception": false,
     "start_time": "2022-02-25T12:14:54.955578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b313c59a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:55.053511Z",
     "iopub.status.busy": "2022-02-25T12:14:55.052809Z",
     "iopub.status.idle": "2022-02-25T12:14:57.780550Z",
     "shell.execute_reply": "2022-02-25T12:14:57.779941Z",
     "shell.execute_reply.started": "2022-02-25T01:03:16.470487Z"
    },
    "papermill": {
     "duration": 2.768649,
     "end_time": "2022-02-25T12:14:57.780711",
     "exception": false,
     "start_time": "2022-02-25T12:14:55.012062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define training epochs\n",
    "EPOCHS = 30\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "\n",
    "with strategy.scope():\n",
    "    pretrained_vgg_model = tf.keras.applications.vgg16.VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False ,\n",
    "        input_shape=[*IMAGE_SIZE, 3]\n",
    "    )\n",
    "    for layer in pretrained_vgg_model.layers:\n",
    "        if layer.name == 'block14_sepconv1' or layer.name == 'block14_sepconv2':\n",
    "           layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    \n",
    "    vgg_model = tf.keras.Sequential([\n",
    "        # To a base pretrained on ImageNet to extract features from images...\n",
    "        pretrained_vgg_model,\n",
    "        # ... attach a new head to act as a classifier.\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b78d72c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:57.856209Z",
     "iopub.status.busy": "2022-02-25T12:14:57.855122Z",
     "iopub.status.idle": "2022-02-25T12:14:57.863672Z",
     "shell.execute_reply": "2022-02-25T12:14:57.863119Z",
     "shell.execute_reply.started": "2022-02-25T01:03:21.456092Z"
    },
    "papermill": {
     "duration": 0.050053,
     "end_time": "2022-02-25T12:14:57.863813",
     "exception": false,
     "start_time": "2022-02-25T12:14:57.813760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 331, 331, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 331, 331, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 331, 331, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 165, 165, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 165, 165, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 165, 165, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 82, 82, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 82, 82, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 82, 82, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 82, 82, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 41, 41, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 41, 41, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 41, 41, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 41, 41, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b0bcf62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:57.940444Z",
     "iopub.status.busy": "2022-02-25T12:14:57.935937Z",
     "iopub.status.idle": "2022-02-25T12:14:57.976427Z",
     "shell.execute_reply": "2022-02-25T12:14:57.975645Z",
     "shell.execute_reply.started": "2022-02-25T01:03:24.606218Z"
    },
    "papermill": {
     "duration": 0.080941,
     "end_time": "2022-02-25T12:14:57.976629",
     "exception": false,
     "start_time": "2022-02-25T12:14:57.895688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 10, 10, 512)       14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               256500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               52104     \n",
      "=================================================================\n",
      "Total params: 15,023,292\n",
      "Trainable params: 308,604\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.01)\n",
    "\n",
    "vgg_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7041c3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T12:14:58.051249Z",
     "iopub.status.busy": "2022-02-25T12:14:58.049892Z",
     "iopub.status.idle": "2022-02-25T14:54:59.314990Z",
     "shell.execute_reply": "2022-02-25T14:54:59.314293Z"
    },
    "papermill": {
     "duration": 9601.305525,
     "end_time": "2022-02-25T14:54:59.315190",
     "exception": false,
     "start_time": "2022-02-25T12:14:58.009665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "897/897 [==============================] - 342s 365ms/step - loss: 2.8150 - sparse_categorical_accuracy: 0.3155 - val_loss: 1.6924 - val_sparse_categorical_accuracy: 0.5508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 12:20:41.036877: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 7283, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1645791641.033559737\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 7283, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.008009999821186066.\n",
      "897/897 [==============================] - 316s 352ms/step - loss: 1.8751 - sparse_categorical_accuracy: 0.4973 - val_loss: 1.5250 - val_sparse_categorical_accuracy: 0.5984\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.004825999994277954.\n",
      "897/897 [==============================] - 317s 354ms/step - loss: 1.6915 - sparse_categorical_accuracy: 0.5425 - val_loss: 1.4145 - val_sparse_categorical_accuracy: 0.6298\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0019603999841213225.\n",
      "897/897 [==============================] - 318s 354ms/step - loss: 1.5687 - sparse_categorical_accuracy: 0.5713 - val_loss: 1.3564 - val_sparse_categorical_accuracy: 0.6396\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0004320800052583216.\n",
      "897/897 [==============================] - 317s 354ms/step - loss: 1.5052 - sparse_categorical_accuracy: 0.5846 - val_loss: 1.3276 - val_sparse_categorical_accuracy: 0.6500\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n",
      "897/897 [==============================] - 317s 354ms/step - loss: 1.4818 - sparse_categorical_accuracy: 0.5922 - val_loss: 1.3189 - val_sparse_categorical_accuracy: 0.6478\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "897/897 [==============================] - 317s 353ms/step - loss: 1.4740 - sparse_categorical_accuracy: 0.5947 - val_loss: 1.3173 - val_sparse_categorical_accuracy: 0.6478\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n",
      "897/897 [==============================] - 319s 355ms/step - loss: 1.4722 - sparse_categorical_accuracy: 0.5928 - val_loss: 1.3163 - val_sparse_categorical_accuracy: 0.6481\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n",
      "897/897 [==============================] - 318s 355ms/step - loss: 1.4708 - sparse_categorical_accuracy: 0.5950 - val_loss: 1.3168 - val_sparse_categorical_accuracy: 0.6472\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 2.6384000000000004e-05.\n",
      "897/897 [==============================] - 322s 359ms/step - loss: 1.4653 - sparse_categorical_accuracy: 0.5947 - val_loss: 1.3157 - val_sparse_categorical_accuracy: 0.6490\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 2.3107200000000005e-05.\n",
      "897/897 [==============================] - 319s 356ms/step - loss: 1.4630 - sparse_categorical_accuracy: 0.5979 - val_loss: 1.3158 - val_sparse_categorical_accuracy: 0.6478\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 2.0485760000000004e-05.\n",
      "897/897 [==============================] - 317s 354ms/step - loss: 1.4707 - sparse_categorical_accuracy: 0.5975 - val_loss: 1.3159 - val_sparse_categorical_accuracy: 0.6481\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1.8388608000000004e-05.\n",
      "897/897 [==============================] - 321s 358ms/step - loss: 1.4718 - sparse_categorical_accuracy: 0.5951 - val_loss: 1.3153 - val_sparse_categorical_accuracy: 0.6475\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1.6710886400000004e-05.\n",
      "897/897 [==============================] - 316s 353ms/step - loss: 1.4694 - sparse_categorical_accuracy: 0.5977 - val_loss: 1.3143 - val_sparse_categorical_accuracy: 0.6475\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1.5368709120000003e-05.\n",
      "897/897 [==============================] - 317s 353ms/step - loss: 1.4664 - sparse_categorical_accuracy: 0.5939 - val_loss: 1.3152 - val_sparse_categorical_accuracy: 0.6478\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1.4294967296000005e-05.\n",
      "897/897 [==============================] - 317s 354ms/step - loss: 1.4641 - sparse_categorical_accuracy: 0.5973 - val_loss: 1.3141 - val_sparse_categorical_accuracy: 0.6494\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1.3435973836800004e-05.\n",
      "897/897 [==============================] - 316s 352ms/step - loss: 1.4662 - sparse_categorical_accuracy: 0.5939 - val_loss: 1.3141 - val_sparse_categorical_accuracy: 0.6481\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.2748779069440003e-05.\n",
      "897/897 [==============================] - 317s 354ms/step - loss: 1.4627 - sparse_categorical_accuracy: 0.5972 - val_loss: 1.3144 - val_sparse_categorical_accuracy: 0.6497\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.2199023255552003e-05.\n",
      "897/897 [==============================] - 317s 353ms/step - loss: 1.4577 - sparse_categorical_accuracy: 0.5981 - val_loss: 1.3139 - val_sparse_categorical_accuracy: 0.6487\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.1759218604441602e-05.\n",
      "897/897 [==============================] - 323s 360ms/step - loss: 1.4571 - sparse_categorical_accuracy: 0.5971 - val_loss: 1.3140 - val_sparse_categorical_accuracy: 0.6481\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.1407374883553282e-05.\n",
      "897/897 [==============================] - 332s 370ms/step - loss: 1.4612 - sparse_categorical_accuracy: 0.5973 - val_loss: 1.3135 - val_sparse_categorical_accuracy: 0.6497\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.1125899906842627e-05.\n",
      "897/897 [==============================] - 322s 359ms/step - loss: 1.4662 - sparse_categorical_accuracy: 0.5956 - val_loss: 1.3132 - val_sparse_categorical_accuracy: 0.6487\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.0900719925474101e-05.\n",
      "897/897 [==============================] - 317s 353ms/step - loss: 1.4617 - sparse_categorical_accuracy: 0.5971 - val_loss: 1.3125 - val_sparse_categorical_accuracy: 0.6497\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0720575940379282e-05.\n",
      "897/897 [==============================] - 318s 354ms/step - loss: 1.4687 - sparse_categorical_accuracy: 0.5962 - val_loss: 1.3139 - val_sparse_categorical_accuracy: 0.6478\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.0576460752303425e-05.\n",
      "897/897 [==============================] - 318s 354ms/step - loss: 1.4587 - sparse_categorical_accuracy: 0.5956 - val_loss: 1.3125 - val_sparse_categorical_accuracy: 0.6490\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.046116860184274e-05.\n",
      "897/897 [==============================] - 338s 377ms/step - loss: 1.4580 - sparse_categorical_accuracy: 0.5981 - val_loss: 1.3128 - val_sparse_categorical_accuracy: 0.6484\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1.0368934881474192e-05.\n",
      "897/897 [==============================] - 318s 355ms/step - loss: 1.4642 - sparse_categorical_accuracy: 0.5951 - val_loss: 1.3124 - val_sparse_categorical_accuracy: 0.6500\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.0295147905179355e-05.\n",
      "897/897 [==============================] - 320s 357ms/step - loss: 1.4538 - sparse_categorical_accuracy: 0.5990 - val_loss: 1.3123 - val_sparse_categorical_accuracy: 0.6494\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.0236118324143484e-05.\n",
      "897/897 [==============================] - 317s 353ms/step - loss: 1.4625 - sparse_categorical_accuracy: 0.5980 - val_loss: 1.3122 - val_sparse_categorical_accuracy: 0.6497\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.0188894659314786e-05.\n",
      "897/897 [==============================] - 317s 354ms/step - loss: 1.4579 - sparse_categorical_accuracy: 0.5983 - val_loss: 1.3119 - val_sparse_categorical_accuracy: 0.6484\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#early_stopping = EarlyStopping(patience=3, verbose=1,restore_best_weights=True)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n",
    "\n",
    "vgg_history = vgg_model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    callbacks=[lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbdb9b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T14:55:16.414118Z",
     "iopub.status.busy": "2022-02-25T14:55:16.412334Z",
     "iopub.status.idle": "2022-02-25T14:55:20.402083Z",
     "shell.execute_reply": "2022-02-25T14:55:20.401370Z"
    },
    "papermill": {
     "duration": 12.451162,
     "end_time": "2022-02-25T14:55:20.402235",
     "exception": false,
     "start_time": "2022-02-25T14:55:07.951073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 14:55:17.295206: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "vgg_model.save('./vggmodel', options=save_locally)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068fd601",
   "metadata": {
    "papermill": {
     "duration": 8.456897,
     "end_time": "2022-02-25T14:55:37.295197",
     "exception": false,
     "start_time": "2022-02-25T14:55:28.838300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "320f747f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T14:55:54.223376Z",
     "iopub.status.busy": "2022-02-25T14:55:54.215760Z",
     "iopub.status.idle": "2022-02-25T14:56:07.734196Z",
     "shell.execute_reply": "2022-02-25T14:56:07.733131Z",
     "shell.execute_reply.started": "2022-02-24T16:11:31.17018Z"
    },
    "papermill": {
     "duration": 21.907933,
     "end_time": "2022-02-25T14:56:07.734352",
     "exception": false,
     "start_time": "2022-02-25T14:55:45.826419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    pretrained_resnet_model = tf.keras.applications.resnet50.ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False ,\n",
    "        input_shape=[*IMAGE_SIZE, 3]\n",
    "    )\n",
    "    for layer in pretrained_resnet_model.layers:\n",
    "        if layer.name == 'block14_sepconv1' or layer.name == 'block14_sepconv2':\n",
    "           layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    \n",
    "    resnet_model = tf.keras.Sequential([\n",
    "        # To a base pretrained on ImageNet to extract features from images...\n",
    "        pretrained_resnet_model,\n",
    "        # ... attach a new head to act as a classifier.\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36f829e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T14:56:24.628669Z",
     "iopub.status.busy": "2022-02-25T14:56:24.627466Z",
     "iopub.status.idle": "2022-02-25T14:56:24.712620Z",
     "shell.execute_reply": "2022-02-25T14:56:24.713192Z",
     "shell.execute_reply.started": "2022-02-24T16:11:41.835989Z"
    },
    "papermill": {
     "duration": 8.467666,
     "end_time": "2022-02-25T14:56:24.713371",
     "exception": false,
     "start_time": "2022-02-25T14:56:16.245705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 331, 331, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 337, 337, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 166, 166, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 166, 166, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 166, 166, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 168, 168, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 83, 83, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 83, 83, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 83, 83, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 83, 83, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 83, 83, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 83, 83, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 83, 83, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 83, 83, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 83, 83, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 83, 83, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 83, 83, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 83, 83, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 83, 83, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 83, 83, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 83, 83, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 83, 83, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 83, 83, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 83, 83, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 83, 83, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 83, 83, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 83, 83, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 83, 83, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 83, 83, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 83, 83, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 83, 83, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 83, 83, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 83, 83, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 83, 83, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 83, 83, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 83, 83, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 83, 83, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 83, 83, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 83, 83, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 42, 42, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 42, 42, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 42, 42, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 42, 42, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 42, 42, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 42, 42, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 42, 42, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 42, 42, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 42, 42, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 42, 42, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 42, 42, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 42, 42, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 42, 42, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 42, 42, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 42, 42, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 42, 42, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 42, 42, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 42, 42, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 42, 42, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 42, 42, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 42, 42, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 42, 42, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 42, 42, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 42, 42, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 42, 42, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 42, 42, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 42, 42, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 42, 42, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 42, 42, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 42, 42, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 42, 42, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 42, 42, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 42, 42, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 42, 42, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 42, 42, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 42, 42, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 42, 42, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 42, 42, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 42, 42, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 42, 42, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 42, 42, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 42, 42, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 21, 21, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 21, 21, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 21, 21, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 21, 21, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 21, 21, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 21, 21, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 21, 21, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 21, 21, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 21, 21, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 21, 21, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 21, 21, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 21, 21, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 21, 21, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 21, 21, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 21, 21, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 21, 21, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 21, 21, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 21, 21, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 21, 21, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 21, 21, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 21, 21, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 21, 21, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 21, 21, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 21, 21, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 21, 21, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 21, 21, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 21, 21, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 21, 21, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 21, 21, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 21, 21, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 21, 21, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 21, 21, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 21, 21, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 21, 21, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 21, 21, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 21, 21, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 21, 21, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 21, 21, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 21, 21, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 21, 21, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 21, 21, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 21, 21, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 21, 21, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 21, 21, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 21, 21, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 21, 21, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 21, 21, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 21, 21, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 21, 21, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 21, 21, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 21, 21, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 11, 11, 512)  524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 11, 11, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 11, 11, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 11, 11, 512)  2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 11, 11, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 11, 11, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 11, 11, 2048) 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 11, 11, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 11, 11, 2048) 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 11, 11, 2048) 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 11, 11, 2048) 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 11, 11, 2048) 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 11, 11, 512)  1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 11, 11, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 11, 11, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 11, 11, 512)  2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 11, 11, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 11, 11, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 11, 11, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 11, 11, 2048) 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 11, 11, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 11, 11, 2048) 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 11, 11, 512)  1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 11, 11, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 11, 11, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 11, 11, 512)  2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 11, 11, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 11, 11, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 11, 11, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 11, 11, 2048) 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 11, 11, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 11, 11, 2048) 0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fe5a2bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T14:56:41.606598Z",
     "iopub.status.busy": "2022-02-25T14:56:41.605786Z",
     "iopub.status.idle": "2022-02-25T14:56:41.649923Z",
     "shell.execute_reply": "2022-02-25T14:56:41.650449Z",
     "shell.execute_reply.started": "2022-02-24T16:11:51.211448Z"
    },
    "papermill": {
     "duration": 8.528859,
     "end_time": "2022-02-25T14:56:41.650615",
     "exception": false,
     "start_time": "2022-02-25T14:56:33.121756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 11, 11, 2048)      23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               1024500   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 104)               52104     \n",
      "=================================================================\n",
      "Total params: 24,664,316\n",
      "Trainable params: 1,076,604\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34e75d22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T14:56:58.402037Z",
     "iopub.status.busy": "2022-02-25T14:56:58.401160Z",
     "iopub.status.idle": "2022-02-25T17:39:41.118739Z",
     "shell.execute_reply": "2022-02-25T17:39:41.119274Z"
    },
    "papermill": {
     "duration": 9771.10364,
     "end_time": "2022-02-25T17:39:41.119499",
     "exception": false,
     "start_time": "2022-02-25T14:56:50.015859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1.0188894520979375e-05.\n",
      "897/897 [==============================] - 336s 358ms/step - loss: 4.3394 - sparse_categorical_accuracy: 0.0568 - val_loss: 4.1576 - val_sparse_categorical_accuracy: 0.0576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 15:02:35.246219: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 180859, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1645801355.245243367\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 180859, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1.81511156167835e-05.\n",
      "897/897 [==============================] - 317s 354ms/step - loss: 4.1918 - sparse_categorical_accuracy: 0.0627 - val_loss: 4.1364 - val_sparse_categorical_accuracy: 0.0702\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 3.089066900021862e-05.\n",
      "897/897 [==============================] - 318s 355ms/step - loss: 4.1630 - sparse_categorical_accuracy: 0.0685 - val_loss: 4.1114 - val_sparse_categorical_accuracy: 0.0727\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 4.2356266961432993e-05.\n",
      "897/897 [==============================] - 329s 367ms/step - loss: 4.1282 - sparse_categorical_accuracy: 0.0759 - val_loss: 4.0790 - val_sparse_categorical_accuracy: 0.0806\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 4.8471253386233007e-05.\n",
      "897/897 [==============================] - 320s 357ms/step - loss: 4.0972 - sparse_categorical_accuracy: 0.0796 - val_loss: 4.0479 - val_sparse_categorical_accuracy: 0.0913\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n",
      "897/897 [==============================] - 316s 353ms/step - loss: 4.0678 - sparse_categorical_accuracy: 0.0851 - val_loss: 4.0233 - val_sparse_categorical_accuracy: 0.0831\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "897/897 [==============================] - 317s 353ms/step - loss: 4.0399 - sparse_categorical_accuracy: 0.0884 - val_loss: 3.9984 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n",
      "897/897 [==============================] - 317s 354ms/step - loss: 4.0221 - sparse_categorical_accuracy: 0.0903 - val_loss: 3.9812 - val_sparse_categorical_accuracy: 0.0951\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n",
      "897/897 [==============================] - 316s 352ms/step - loss: 4.0042 - sparse_categorical_accuracy: 0.0919 - val_loss: 3.9689 - val_sparse_categorical_accuracy: 0.1061\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 2.6384000000000004e-05.\n",
      "897/897 [==============================] - 322s 359ms/step - loss: 3.9906 - sparse_categorical_accuracy: 0.0937 - val_loss: 3.9578 - val_sparse_categorical_accuracy: 0.0947\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 2.3107200000000005e-05.\n",
      "897/897 [==============================] - 332s 370ms/step - loss: 3.9840 - sparse_categorical_accuracy: 0.0958 - val_loss: 3.9504 - val_sparse_categorical_accuracy: 0.0897\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 2.0485760000000004e-05.\n",
      "897/897 [==============================] - 323s 360ms/step - loss: 3.9731 - sparse_categorical_accuracy: 0.0970 - val_loss: 3.9401 - val_sparse_categorical_accuracy: 0.1048\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1.8388608000000004e-05.\n",
      "897/897 [==============================] - 330s 368ms/step - loss: 3.9664 - sparse_categorical_accuracy: 0.0967 - val_loss: 3.9329 - val_sparse_categorical_accuracy: 0.1029\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1.6710886400000004e-05.\n",
      "897/897 [==============================] - 329s 367ms/step - loss: 3.9578 - sparse_categorical_accuracy: 0.0991 - val_loss: 3.9262 - val_sparse_categorical_accuracy: 0.0995\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1.5368709120000003e-05.\n",
      "897/897 [==============================] - 344s 384ms/step - loss: 3.9563 - sparse_categorical_accuracy: 0.0999 - val_loss: 3.9183 - val_sparse_categorical_accuracy: 0.1105\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1.4294967296000005e-05.\n",
      "897/897 [==============================] - 321s 358ms/step - loss: 3.9477 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.9168 - val_sparse_categorical_accuracy: 0.0925\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1.3435973836800004e-05.\n",
      "897/897 [==============================] - 331s 369ms/step - loss: 3.9410 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.9130 - val_sparse_categorical_accuracy: 0.1020\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.2748779069440003e-05.\n",
      "897/897 [==============================] - 324s 361ms/step - loss: 3.9364 - sparse_categorical_accuracy: 0.1022 - val_loss: 3.9076 - val_sparse_categorical_accuracy: 0.1029\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.2199023255552003e-05.\n",
      "897/897 [==============================] - 331s 369ms/step - loss: 3.9332 - sparse_categorical_accuracy: 0.1027 - val_loss: 3.9020 - val_sparse_categorical_accuracy: 0.1114\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.1759218604441602e-05.\n",
      "897/897 [==============================] - 322s 359ms/step - loss: 3.9308 - sparse_categorical_accuracy: 0.1022 - val_loss: 3.8991 - val_sparse_categorical_accuracy: 0.1086\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.1407374883553282e-05.\n",
      "897/897 [==============================] - 336s 375ms/step - loss: 3.9275 - sparse_categorical_accuracy: 0.1014 - val_loss: 3.8956 - val_sparse_categorical_accuracy: 0.1032\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.1125899906842627e-05.\n",
      "897/897 [==============================] - 325s 363ms/step - loss: 3.9273 - sparse_categorical_accuracy: 0.1015 - val_loss: 3.8910 - val_sparse_categorical_accuracy: 0.1095\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.0900719925474101e-05.\n",
      "897/897 [==============================] - 318s 355ms/step - loss: 3.9205 - sparse_categorical_accuracy: 0.1042 - val_loss: 3.8896 - val_sparse_categorical_accuracy: 0.1165\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0720575940379282e-05.\n",
      "897/897 [==============================] - 323s 360ms/step - loss: 3.9145 - sparse_categorical_accuracy: 0.1048 - val_loss: 3.8864 - val_sparse_categorical_accuracy: 0.1117\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.0576460752303425e-05.\n",
      "897/897 [==============================] - 329s 366ms/step - loss: 3.9117 - sparse_categorical_accuracy: 0.1068 - val_loss: 3.8838 - val_sparse_categorical_accuracy: 0.1111\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.046116860184274e-05.\n",
      "897/897 [==============================] - 333s 372ms/step - loss: 3.9099 - sparse_categorical_accuracy: 0.1054 - val_loss: 3.8787 - val_sparse_categorical_accuracy: 0.1155\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1.0368934881474192e-05.\n",
      "897/897 [==============================] - 322s 359ms/step - loss: 3.9066 - sparse_categorical_accuracy: 0.1059 - val_loss: 3.8774 - val_sparse_categorical_accuracy: 0.1108\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.0295147905179355e-05.\n",
      "897/897 [==============================] - 321s 358ms/step - loss: 3.9008 - sparse_categorical_accuracy: 0.1085 - val_loss: 3.8731 - val_sparse_categorical_accuracy: 0.1199\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.0236118324143484e-05.\n",
      "897/897 [==============================] - 319s 356ms/step - loss: 3.9001 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.8710 - val_sparse_categorical_accuracy: 0.1171\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.0188894659314786e-05.\n",
      "897/897 [==============================] - 340s 379ms/step - loss: 3.9028 - sparse_categorical_accuracy: 0.1067 - val_loss: 3.8701 - val_sparse_categorical_accuracy: 0.1146\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resnet_history = resnet_model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    callbacks=[lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76213966",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T17:40:14.638157Z",
     "iopub.status.busy": "2022-02-25T17:40:14.630800Z",
     "iopub.status.idle": "2022-02-25T17:40:51.423556Z",
     "shell.execute_reply": "2022-02-25T17:40:51.420329Z"
    },
    "papermill": {
     "duration": 53.539494,
     "end_time": "2022-02-25T17:40:51.423716",
     "exception": false,
     "start_time": "2022-02-25T17:39:57.884222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "resnet_model.save('./resnetmodel', options=save_locally)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c90736",
   "metadata": {
    "papermill": {
     "duration": 17.02603,
     "end_time": "2022-02-25T17:41:25.298285",
     "exception": false,
     "start_time": "2022-02-25T17:41:08.272255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## InceptionNet V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb5cd07b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T17:41:58.770555Z",
     "iopub.status.busy": "2022-02-25T17:41:58.769862Z",
     "iopub.status.idle": "2022-02-25T17:42:17.832433Z",
     "shell.execute_reply": "2022-02-25T17:42:17.831854Z",
     "shell.execute_reply.started": "2022-02-24T16:16:11.757117Z"
    },
    "papermill": {
     "duration": 35.774761,
     "end_time": "2022-02-25T17:42:17.832604",
     "exception": false,
     "start_time": "2022-02-25T17:41:42.057843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    pretrained_inception_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "        weights='imagenet',\n",
    "        include_top=False ,\n",
    "        input_shape=[*IMAGE_SIZE, 3]\n",
    "    )\n",
    "    for layer in pretrained_inception_model.layers:\n",
    "        if layer.name == 'block14_sepconv1' or layer.name == 'block14_sepconv2':\n",
    "           layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    \n",
    "    inception_model = tf.keras.Sequential([\n",
    "        # To a base pretrained on ImageNet to extract features from images...\n",
    "        pretrained_inception_model,\n",
    "        # ... attach a new head to act as a classifier.\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7cb88fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T17:42:51.593204Z",
     "iopub.status.busy": "2022-02-25T17:42:51.592236Z",
     "iopub.status.idle": "2022-02-25T17:42:51.725045Z",
     "shell.execute_reply": "2022-02-25T17:42:51.725865Z",
     "shell.execute_reply.started": "2022-02-24T16:16:34.423623Z"
    },
    "papermill": {
     "duration": 17.00242,
     "end_time": "2022-02-25T17:42:51.726146",
     "exception": false,
     "start_time": "2022-02-25T17:42:34.723726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 331, 331, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 165, 165, 32) 864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 165, 165, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 165, 165, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 163, 163, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 163, 163, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 163, 163, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 163, 163, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 163, 163, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 163, 163, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 81, 81, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 81, 81, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 81, 81, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 81, 81, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 79, 79, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 79, 79, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 79, 79, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 39, 39, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 39, 39, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 39, 39, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 39, 39, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 39, 39, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 39, 39, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 39, 39, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 39, 39, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 39, 39, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 39, 39, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 39, 39, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 39, 39, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 39, 39, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 39, 39, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 39, 39, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 39, 39, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 39, 39, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 39, 39, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 39, 39, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 39, 39, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 39, 39, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 39, 39, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 39, 39, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 39, 39, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 39, 39, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 39, 39, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 39, 39, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 39, 39, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 39, 39, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 39, 39, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 39, 39, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 39, 39, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 39, 39, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 39, 39, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 39, 39, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 39, 39, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 39, 39, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 39, 39, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 39, 39, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 39, 39, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 39, 39, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 39, 39, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 39, 39, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 39, 39, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 39, 39, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 39, 39, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 39, 39, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 39, 39, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 39, 39, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 39, 39, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 39, 39, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 39, 39, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 39, 39, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 39, 39, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 39, 39, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 39, 39, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 39, 39, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 39, 39, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 39, 39, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 39, 39, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 39, 39, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 39, 39, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 39, 39, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 39, 39, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 39, 39, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 39, 39, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 39, 39, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 39, 39, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 39, 39, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 39, 39, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 39, 39, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 39, 39, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 39, 39, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 39, 39, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 39, 39, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 39, 39, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 19, 19, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 19, 19, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 19, 19, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 19, 19, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 19, 19, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 19, 19, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 19, 19, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 19, 19, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 19, 19, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 19, 19, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 19, 19, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 19, 19, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 19, 19, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 19, 19, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 19, 19, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 19, 19, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 19, 19, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 19, 19, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 19, 19, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 19, 19, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 19, 19, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 19, 19, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 19, 19, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 19, 19, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 19, 19, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 19, 19, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 19, 19, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 19, 19, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 19, 19, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 19, 19, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 19, 19, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 19, 19, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 19, 19, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 19, 19, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 19, 19, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 19, 19, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 19, 19, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 19, 19, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 19, 19, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 19, 19, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 19, 19, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 19, 19, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 19, 19, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 19, 19, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 19, 19, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 19, 19, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 19, 19, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 19, 19, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 19, 19, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 19, 19, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 19, 19, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 19, 19, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 19, 19, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 19, 19, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 19, 19, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 19, 19, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 19, 19, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 19, 19, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 19, 19, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 19, 19, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 19, 19, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 19, 19, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 19, 19, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 19, 19, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 19, 19, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 19, 19, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 19, 19, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 19, 19, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 19, 19, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 19, 19, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 19, 19, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 19, 19, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 19, 19, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 19, 19, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 19, 19, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 19, 19, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 19, 19, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 19, 19, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 19, 19, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 19, 19, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 19, 19, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 19, 19, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 19, 19, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 19, 19, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 19, 19, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 19, 19, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 19, 19, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 19, 19, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 19, 19, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 19, 19, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 19, 19, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 19, 19, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 19, 19, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 19, 19, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 19, 19, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 19, 19, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 19, 19, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 19, 19, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 19, 19, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 19, 19, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 19, 19, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 19, 19, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 19, 19, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 19, 19, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 19, 19, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 19, 19, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 19, 19, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 19, 19, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 19, 19, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 19, 19, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 19, 19, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 19, 19, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 19, 19, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 19, 19, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 19, 19, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 19, 19, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 19, 19, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 19, 19, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 19, 19, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 19, 19, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 19, 19, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 19, 19, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 19, 19, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 19, 19, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 19, 19, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 19, 19, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 19, 19, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 19, 19, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 19, 19, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 19, 19, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 19, 19, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 19, 19, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 19, 19, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 19, 19, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 19, 19, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 19, 19, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 19, 19, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 19, 19, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 19, 19, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 19, 19, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 19, 19, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 19, 19, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 19, 19, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 19, 19, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 19, 19, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 19, 19, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 19, 19, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 19, 19, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 9, 9, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 9, 9, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 9, 9, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 9, 9, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 9, 9, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 9, 9, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 9, 9, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 9, 9, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 9, 9, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 9, 9, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 9, 9, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 9, 9, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 9, 9, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 9, 9, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 9, 9, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 9, 9, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 9, 9, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 9, 9, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 9, 9, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 9, 9, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 9, 9, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 9, 9, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 9, 9, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 9, 9, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 9, 9, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 9, 9, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 9, 9, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 9, 9, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 9, 9, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 9, 9, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 9, 9, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 9, 9, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 9, 9, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 9, 9, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 9, 9, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 9, 9, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 9, 9, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 9, 9, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 9, 9, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 9, 9, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 9, 9, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 9, 9, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 9, 9, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 9, 9, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 9, 9, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 9, 9, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 9, 9, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 9, 9, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 9, 9, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 9, 9, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 9, 9, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 9, 9, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 9, 9, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 9, 9, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 9, 9, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 9, 9, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 9, 9, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 9, 9, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 9, 9, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 9, 9, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 9, 9, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 9, 9, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 9, 9, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 9, 9, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 9, 9, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 9, 9, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 9, 9, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 9, 9, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 9, 9, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 9, 9, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0a45c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T17:43:25.516631Z",
     "iopub.status.busy": "2022-02-25T17:43:25.515917Z",
     "iopub.status.idle": "2022-02-25T17:43:25.562360Z",
     "shell.execute_reply": "2022-02-25T17:43:25.563103Z",
     "shell.execute_reply.started": "2022-02-24T16:17:29.661899Z"
    },
    "papermill": {
     "duration": 16.832047,
     "end_time": "2022-02-25T17:43:25.563337",
     "exception": false,
     "start_time": "2022-02-25T17:43:08.731290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 9, 9, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               1024500   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 104)               52104     \n",
      "=================================================================\n",
      "Total params: 22,879,388\n",
      "Trainable params: 1,076,604\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inception_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "\n",
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25010704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T17:43:59.135247Z",
     "iopub.status.busy": "2022-02-25T17:43:59.134262Z",
     "iopub.status.idle": "2022-02-25T20:26:51.634791Z",
     "shell.execute_reply": "2022-02-25T20:26:51.635553Z"
    },
    "papermill": {
     "duration": 9789.341505,
     "end_time": "2022-02-25T20:26:51.635807",
     "exception": false,
     "start_time": "2022-02-25T17:43:42.294302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1.0188894520979375e-05.\n",
      "897/897 [==============================] - 365s 374ms/step - loss: 3.5150 - sparse_categorical_accuracy: 0.2521 - val_loss: 2.4607 - val_sparse_categorical_accuracy: 0.4539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 17:50:04.599304: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 361321, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1645811404.599085951\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 361321, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1.81511156167835e-05.\n",
      "897/897 [==============================] - 321s 358ms/step - loss: 2.2886 - sparse_categorical_accuracy: 0.4794 - val_loss: 1.8120 - val_sparse_categorical_accuracy: 0.5936\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 3.089066900021862e-05.\n",
      "897/897 [==============================] - 333s 372ms/step - loss: 1.7034 - sparse_categorical_accuracy: 0.6009 - val_loss: 1.4035 - val_sparse_categorical_accuracy: 0.6708\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 4.2356266961432993e-05.\n",
      "897/897 [==============================] - 330s 368ms/step - loss: 1.3354 - sparse_categorical_accuracy: 0.6764 - val_loss: 1.1560 - val_sparse_categorical_accuracy: 0.7271\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 4.8471253386233007e-05.\n",
      "897/897 [==============================] - 332s 370ms/step - loss: 1.1062 - sparse_categorical_accuracy: 0.7263 - val_loss: 1.0129 - val_sparse_categorical_accuracy: 0.7535\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n",
      "897/897 [==============================] - 328s 366ms/step - loss: 0.9484 - sparse_categorical_accuracy: 0.7592 - val_loss: 0.9264 - val_sparse_categorical_accuracy: 0.7705\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "897/897 [==============================] - 328s 366ms/step - loss: 0.8535 - sparse_categorical_accuracy: 0.7782 - val_loss: 0.8753 - val_sparse_categorical_accuracy: 0.7841\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n",
      "897/897 [==============================] - 331s 369ms/step - loss: 0.7917 - sparse_categorical_accuracy: 0.7937 - val_loss: 0.8445 - val_sparse_categorical_accuracy: 0.7923\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n",
      "897/897 [==============================] - 322s 359ms/step - loss: 0.7483 - sparse_categorical_accuracy: 0.8031 - val_loss: 0.8224 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 2.6384000000000004e-05.\n",
      "897/897 [==============================] - 322s 359ms/step - loss: 0.7126 - sparse_categorical_accuracy: 0.8132 - val_loss: 0.8096 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 2.3107200000000005e-05.\n",
      "897/897 [==============================] - 322s 359ms/step - loss: 0.6927 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.7963 - val_sparse_categorical_accuracy: 0.7995\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 2.0485760000000004e-05.\n",
      "897/897 [==============================] - 323s 361ms/step - loss: 0.6675 - sparse_categorical_accuracy: 0.8225 - val_loss: 0.7855 - val_sparse_categorical_accuracy: 0.8048\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1.8388608000000004e-05.\n",
      "897/897 [==============================] - 318s 355ms/step - loss: 0.6524 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.7768 - val_sparse_categorical_accuracy: 0.8030\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1.6710886400000004e-05.\n",
      "897/897 [==============================] - 322s 359ms/step - loss: 0.6341 - sparse_categorical_accuracy: 0.8315 - val_loss: 0.7677 - val_sparse_categorical_accuracy: 0.8052\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1.5368709120000003e-05.\n",
      "897/897 [==============================] - 339s 378ms/step - loss: 0.6312 - sparse_categorical_accuracy: 0.8322 - val_loss: 0.7625 - val_sparse_categorical_accuracy: 0.8080\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1.4294967296000005e-05.\n",
      "897/897 [==============================] - 321s 358ms/step - loss: 0.6166 - sparse_categorical_accuracy: 0.8341 - val_loss: 0.7577 - val_sparse_categorical_accuracy: 0.8105\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1.3435973836800004e-05.\n",
      "897/897 [==============================] - 329s 367ms/step - loss: 0.6104 - sparse_categorical_accuracy: 0.8344 - val_loss: 0.7515 - val_sparse_categorical_accuracy: 0.8133\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.2748779069440003e-05.\n",
      "897/897 [==============================] - 321s 359ms/step - loss: 0.6001 - sparse_categorical_accuracy: 0.8378 - val_loss: 0.7519 - val_sparse_categorical_accuracy: 0.8102\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.2199023255552003e-05.\n",
      "897/897 [==============================] - 318s 355ms/step - loss: 0.5961 - sparse_categorical_accuracy: 0.8392 - val_loss: 0.7463 - val_sparse_categorical_accuracy: 0.8115\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.1759218604441602e-05.\n",
      "897/897 [==============================] - 322s 359ms/step - loss: 0.5828 - sparse_categorical_accuracy: 0.8422 - val_loss: 0.7431 - val_sparse_categorical_accuracy: 0.8130\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.1407374883553282e-05.\n",
      "897/897 [==============================] - 317s 354ms/step - loss: 0.5777 - sparse_categorical_accuracy: 0.8433 - val_loss: 0.7390 - val_sparse_categorical_accuracy: 0.8143\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.1125899906842627e-05.\n",
      "897/897 [==============================] - 325s 363ms/step - loss: 0.5704 - sparse_categorical_accuracy: 0.8450 - val_loss: 0.7366 - val_sparse_categorical_accuracy: 0.8155\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.0900719925474101e-05.\n",
      "897/897 [==============================] - 321s 358ms/step - loss: 0.5709 - sparse_categorical_accuracy: 0.8454 - val_loss: 0.7352 - val_sparse_categorical_accuracy: 0.8155\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0720575940379282e-05.\n",
      "897/897 [==============================] - 321s 358ms/step - loss: 0.5633 - sparse_categorical_accuracy: 0.8465 - val_loss: 0.7324 - val_sparse_categorical_accuracy: 0.8159\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.0576460752303425e-05.\n",
      "897/897 [==============================] - 330s 368ms/step - loss: 0.5619 - sparse_categorical_accuracy: 0.8461 - val_loss: 0.7293 - val_sparse_categorical_accuracy: 0.8146\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.046116860184274e-05.\n",
      "897/897 [==============================] - 318s 355ms/step - loss: 0.5550 - sparse_categorical_accuracy: 0.8489 - val_loss: 0.7269 - val_sparse_categorical_accuracy: 0.8178\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1.0368934881474192e-05.\n",
      "897/897 [==============================] - 324s 361ms/step - loss: 0.5440 - sparse_categorical_accuracy: 0.8515 - val_loss: 0.7252 - val_sparse_categorical_accuracy: 0.8165\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.0295147905179355e-05.\n",
      "897/897 [==============================] - 327s 365ms/step - loss: 0.5411 - sparse_categorical_accuracy: 0.8522 - val_loss: 0.7217 - val_sparse_categorical_accuracy: 0.8178\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.0236118324143484e-05.\n",
      "897/897 [==============================] - 318s 355ms/step - loss: 0.5395 - sparse_categorical_accuracy: 0.8525 - val_loss: 0.7209 - val_sparse_categorical_accuracy: 0.8187\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.0188894659314786e-05.\n",
      "897/897 [==============================] - 322s 359ms/step - loss: 0.5398 - sparse_categorical_accuracy: 0.8517 - val_loss: 0.7182 - val_sparse_categorical_accuracy: 0.8203\n"
     ]
    }
   ],
   "source": [
    "inception_history = inception_model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    callbacks=[lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63b483a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T20:27:42.399551Z",
     "iopub.status.busy": "2022-02-25T20:27:42.398559Z",
     "iopub.status.idle": "2022-02-25T20:28:45.410987Z",
     "shell.execute_reply": "2022-02-25T20:28:45.406976Z"
    },
    "papermill": {
     "duration": 88.473422,
     "end_time": "2022-02-25T20:28:45.411180",
     "exception": false,
     "start_time": "2022-02-25T20:27:16.937758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "inception_model.save('./inceptionmodel', options=save_locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc49b0e",
   "metadata": {
    "papermill": {
     "duration": 25.252508,
     "end_time": "2022-02-25T20:29:36.181498",
     "exception": false,
     "start_time": "2022-02-25T20:29:10.928990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29731.608816,
   "end_time": "2022-02-25T20:30:04.716935",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-25T12:14:33.108119",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
