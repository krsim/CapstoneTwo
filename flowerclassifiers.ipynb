{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Import libraries\nimport torch \nimport torchvision\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch import nn, optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport glob\nimport tensorflow as tf\nAUTO = tf.data.experimental.AUTOTUNE\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:23:00.642575Z","iopub.execute_input":"2022-02-11T13:23:00.642846Z","iopub.status.idle":"2022-02-11T13:23:06.407042Z","shell.execute_reply.started":"2022-02-11T13:23:00.642812Z","shell.execute_reply":"2022-02-11T13:23:06.406280Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def load_data(root_path, dir, batch_size):\n    transform_dict = {'norm' : transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])}\n    \n    data = datasets.ImageFolder(root=root_path + dir, transform=transform_dict['norm'])\n    \n    data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=2)\n    \n    return data_loader","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:23:09.668115Z","iopub.execute_input":"2022-02-11T13:23:09.668839Z","iopub.status.idle":"2022-02-11T13:23:09.674277Z","shell.execute_reply.started":"2022-02-11T13:23:09.668785Z","shell.execute_reply":"2022-02-11T13:23:09.673469Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# numpy and matplotlib defaults\nnp.set_printoptions(threshold=15, linewidth=80)\n\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n        numpy_labels = [None for _ in enumerate(numpy_images)]\n    # If no labels, only image IDs, return None for labels (this is the case for test data)\n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n    \ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()\n\ndef display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(15,15))\n    ax = plt.gca()\n    ax.matshow(cmat, cmap='Reds')\n    ax.set_xticks(range(len(CLASSES)))\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n    ax.set_yticks(range(len(CLASSES)))\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall)\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n    plt.show()\n    \ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:23:10.924377Z","iopub.execute_input":"2022-02-11T13:23:10.925034Z","iopub.status.idle":"2022-02-11T13:23:10.952191Z","shell.execute_reply.started":"2022-02-11T13:23:10.924980Z","shell.execute_reply":"2022-02-11T13:23:10.951490Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)  # image format uint8 [0,255]\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\ndef data_augment(image, label):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    #image = tf.image.random_saturation(image, 0, 2)\n    return image, label   \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    #dataset = dataset.map(data_augment)\n    #dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    #dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(15,15))\n    ax = plt.gca()\n    ax.matshow(cmat, cmap='Reds')\n    ax.set_xticks(range(len(CLASSES)))\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n    ax.set_yticks(range(len(CLASSES)))\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall)\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n    plt.show()\n\nIMAGE_SIZE = [224, 224]\nBATCH_SIZE = 16 \n\nPATH_SELECT = { # available image sizes\n    192: '../input/dataset' + '/tfrecords-jpeg-192x192',\n    224: '../input/dataset' + '/tfrecords-jpeg-224x224',\n    331: '../input/dataset' + '/tfrecords-jpeg-331x331',\n    512: '../input/dataset' + '/tfrecords-jpeg-512x512'\n}\n\nPATH = PATH_SELECT[224]\n\nTRAINING_FILENAMES = tf.io.gfile.glob(PATH + '/train/*.tfrec')\nVALIDATION_FILENAMES = tf.io.gfile.glob(PATH + '/val/*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(PATH + '/test/*.tfrec')\n\ndataset = get_training_dataset()\nimages = []\nlabels = []\n\nfor img, lbl in dataset:\n    images.append(img)\n    labels.append(lbl)\n    \nimg_list=[]\nfor i in range(images.__len__()):\n    for j in range(images[i].__len__()):\n        img_list.append(images[i][j,:,:,:])\n        \nlab_list = list()\nfor label in labels:\n    x = label.numpy().tolist()\n    lab_list+=x\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:23:11.723322Z","iopub.execute_input":"2022-02-11T13:23:11.723808Z","iopub.status.idle":"2022-02-11T13:23:30.921552Z","shell.execute_reply.started":"2022-02-11T13:23:11.723750Z","shell.execute_reply":"2022-02-11T13:23:30.920812Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2022-02-11 13:23:11.833835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-02-11 13:23:11.834836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-02-11 13:23:11.835469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-02-11 13:23:11.837284: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-02-11 13:23:11.838378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-02-11 13:23:11.839077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-02-11 13:23:11.839698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-02-11 13:23:16.508981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-02-11 13:23:16.509705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-02-11 13:23:16.510371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-02-11 13:23:16.510947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14959 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2022-02-11 13:23:16.979362: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\nfor i in range(len(lab_list)):\n    img = np.array(img_list[i]).astype(np.uint8)\n    lbl = lab_list[i]\n    lbl = str(lbl)\n    if not os.path.exists(\"../output/kaggle/working/dataset224/train/\"+lbl):\n        os.makedirs(\"../output/kaggle/working/dataset224/train/\"+lbl)\n    im = Image.fromarray(img)\n    im.save(\"../output/kaggle/working/dataset224/train/\"+lbl+\"/\"+str(i)+\".jpeg\")\n\ndataset = get_validation_dataset()\nval_images = []\nval_labels = []\n\nfor img, lbl in dataset:\n    val_images.append(img)\n    val_labels.append(lbl)\n    \nval_img_list=[]\nfor i in range(val_images.__len__()):\n    for j in range(val_images[i].__len__()):\n        img_list.append(val_images[i][j,:,:,:])\n        \nval_lab_list = list()\nfor label in val_labels:\n    x = label.numpy().tolist()\n    val_lab_list+=x\n    \nfor i in range(len(lab_list)):\n    img = np.array(img_list[i]).astype(np.uint8)\n    lbl = lab_list[i]\n    lbl = str(lbl)\n    if not os.path.exists(\"../output/kaggle/working/dataset224/val/\"+lbl):\n        os.makedirs(\"../output/kaggle/working/dataset224/val/\"+lbl)\n    im = Image.fromarray(img)\n    im.save(\"../output/kaggle/working/dataset224/val/\"+lbl+\"/\"+str(i)+\".jpeg\")","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:23:30.923176Z","iopub.execute_input":"2022-02-11T13:23:30.923435Z","iopub.status.idle":"2022-02-11T13:24:32.930116Z","shell.execute_reply.started":"2022-02-11T13:23:30.923402Z","shell.execute_reply":"2022-02-11T13:24:32.929207Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#define trainloader and test loader\ntrainloader = load_data('../output/kaggle/working/dataset224', '/train', 64)\ntestloader = load_data('../output/kaggle/working/dataset224', '/val', 64)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:24:32.933719Z","iopub.execute_input":"2022-02-11T13:24:32.934370Z","iopub.status.idle":"2022-02-11T13:24:33.176149Z","shell.execute_reply.started":"2022-02-11T13:24:32.934339Z","shell.execute_reply":"2022-02-11T13:24:33.175039Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"\n## Simple Model","metadata":{}},{"cell_type":"code","source":"#Define the model architecture\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        #Declare all the layers for extraction\n        self.features = nn.Sequential(nn.Conv2d(3, 4, kernel_size=3, stride=1, padding=1),\n          nn.BatchNorm2d(4),\n          nn.ReLU(inplace=True),\n          nn.MaxPool2d(kernel_size=2, stride=2),\n          # Defining another 2D convolution layer\n          nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n          nn.BatchNorm2d(4),\n          nn.ReLU(inplace=True),\n          nn.MaxPool2d(kernel_size=2, stride=2)\n      )\n        \n        #Declare all layers for classification\n        self.classifier = nn.Sequential(nn.Linear(56 * 56 * 4, 104))\n        \n    def forward(self, x):\n        #Apply feature extractor to x\n        x = self.features(x)\n        \n        #Squueze the 3 spatial dimensions into one\n        x = x.view(x.size(0), -1)\n        \n        #Classify\n        x = self.classifier(x)\n        \n        return x\n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:25:00.443164Z","iopub.execute_input":"2022-02-11T13:25:00.443435Z","iopub.status.idle":"2022-02-11T13:25:00.452507Z","shell.execute_reply.started":"2022-02-11T13:25:00.443407Z","shell.execute_reply":"2022-02-11T13:25:00.451816Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Define the model\nmodel = Net()\n\n# Define the optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\n#Define the loss function\ncriterion = nn.CrossEntropyLoss()\n\n# checking if GPU is available\n#if torch.cuda.is_available():\n #   model = model.cuda()\n  #  criterion = criterion.cuda()\n    \nprint(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:27:58.749508Z","iopub.execute_input":"2022-02-11T13:27:58.750244Z","iopub.status.idle":"2022-02-11T13:27:58.768927Z","shell.execute_reply.started":"2022-02-11T13:27:58.750205Z","shell.execute_reply":"2022-02-11T13:27:58.768085Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Net(\n  (features): Sequential(\n    (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU(inplace=True)\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=12544, out_features=104, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Train the model for 10 epochs\nfor epoch in range(10):\n    running_loss = 0\n    for i, data in enumerate(trainloader, 0):\n        \n        \n        #Get inputs\n        inputs, labels = data\n        \n        if torch.cuda.is_available():\n          inputs = inputs.cuda()\n          labels = labels.cuda()\n        \n        #zero the parameter gradients\n        optimizer.zero_grad()\n        \n        #Forward + backward + optimize\n        outputs = model(inputs)\n        \n        loss = criterion(outputs, labels)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        running_loss += loss.item()\n    \n        \n    print(\"Epoch {} - Training loss: {}\".format(epoch+1, running_loss/len(trainloader)))\n    print(output)\n  ","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:28:00.038775Z","iopub.execute_input":"2022-02-11T13:28:00.039433Z","iopub.status.idle":"2022-02-11T13:28:00.787317Z","shell.execute_reply.started":"2022-02-11T13:28:00.039394Z","shell.execute_reply":"2022-02-11T13:28:00.785890Z"},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2346205638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#Forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/1284570453.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#Apply feature extractor to x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#Squueze the 3 spatial dimensions into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"],"ename":"RuntimeError","evalue":"Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same","output_type":"error"}]},{"cell_type":"code","source":"from torchvision import models","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:29:07.517657Z","iopub.execute_input":"2022-02-11T13:29:07.518467Z","iopub.status.idle":"2022-02-11T13:29:07.523273Z","shell.execute_reply.started":"2022-02-11T13:29:07.518426Z","shell.execute_reply":"2022-02-11T13:29:07.522524Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train_model(model, dataloaders, testloaders, criterion, optimizer, device, num_epochs=25, is_train=True):\n    since = time.time()\n    \n    acc_history = []\n    loss_history = []\n\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        # Iterate over data.\n        for inputs, labels in dataloaders:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            model.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            _, preds = torch.max(outputs, 1)\n\n            # backward\n            loss.backward()\n            optimizer.step()\n\n            # statistics\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(dataloaders.dataset)\n        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n\n        print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n\n        if epoch_acc > best_acc:\n            best_acc = epoch_acc\n        elif epoch_acc < best_acc:\n            break\n\n        acc_history.append(epoch_acc.item())\n        loss_history.append(epoch_loss)\n        \n        if not os.path.exists(\"../output/kaggle/working/temp\"):\n            os.makedirs(\"../output/kaggle/working/temp\")\n        \n        torch.save(model.state_dict(), os.path.join('../output/kaggle/working/temp', '{0:0=2d}.pth'.format(epoch)))\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best Acc: {:4f}'.format(best_acc))\n    \n   \n    \n    return acc_history, loss_history, model","metadata":{"execution":{"iopub.status.busy":"2022-02-11T14:35:52.097102Z","iopub.execute_input":"2022-02-11T14:35:52.097447Z","iopub.status.idle":"2022-02-11T14:35:52.119004Z","shell.execute_reply.started":"2022-02-11T14:35:52.097412Z","shell.execute_reply":"2022-02-11T14:35:52.118332Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"alexnet = models.alexnet(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:29:46.238955Z","iopub.execute_input":"2022-02-11T13:29:46.239840Z","iopub.status.idle":"2022-02-11T13:29:55.831279Z","shell.execute_reply.started":"2022-02-11T13:29:46.239777Z","shell.execute_reply":"2022-02-11T13:29:55.830533Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/233M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e2cef8cac6845e685da492f26bee88e"}},"metadata":{}}]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) ","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:42:54.582353Z","iopub.execute_input":"2022-02-11T13:42:54.582654Z","iopub.status.idle":"2022-02-11T13:42:54.592196Z","shell.execute_reply.started":"2022-02-11T13:42:54.582622Z","shell.execute_reply":"2022-02-11T13:42:54.591426Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"alexnet.eval()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:30:01.737555Z","iopub.execute_input":"2022-02-11T13:30:01.738126Z","iopub.status.idle":"2022-02-11T13:30:01.746256Z","shell.execute_reply.started":"2022-02-11T13:30:01.738087Z","shell.execute_reply":"2022-02-11T13:30:01.745236Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"#update second classifier\nalexnet.classifier[4] = nn.Linear(4096, 1024)\n\n#update output layer\nalexnet.classifier[6] = nn.Linear(1024, 104)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:30:02.849031Z","iopub.execute_input":"2022-02-11T13:30:02.849686Z","iopub.status.idle":"2022-02-11T13:30:02.918157Z","shell.execute_reply.started":"2022-02-11T13:30:02.849643Z","shell.execute_reply":"2022-02-11T13:30:02.917174Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"alexnet.eval()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:30:07.695042Z","iopub.execute_input":"2022-02-11T13:30:07.695421Z","iopub.status.idle":"2022-02-11T13:30:07.703345Z","shell.execute_reply.started":"2022-02-11T13:30:07.695378Z","shell.execute_reply":"2022-02-11T13:30:07.702256Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=1024, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=1024, out_features=104, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"#Loss\ncriterion = nn.CrossEntropyLoss()\n\n#optimizer\n#optimizer = optim.SGD(alexnet.parameters(), lr = 0.001, momentum = 0.9)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T14:17:51.556460Z","iopub.execute_input":"2022-02-11T14:17:51.556769Z","iopub.status.idle":"2022-02-11T14:17:51.561779Z","shell.execute_reply.started":"2022-02-11T14:17:51.556738Z","shell.execute_reply":"2022-02-11T14:17:51.560610Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Here we only want to update the gradient for the classifier layer that we initialized.\nparams_to_update = []\nfor name,param in alexnet.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n        print(\"\\t\",name)\n            \noptimizer = optim.SGD(params_to_update, lr = 0.001, momentum = 0.9)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T14:17:52.866676Z","iopub.execute_input":"2022-02-11T14:17:52.867460Z","iopub.status.idle":"2022-02-11T14:17:52.877912Z","shell.execute_reply.started":"2022-02-11T14:17:52.867408Z","shell.execute_reply":"2022-02-11T14:17:52.877165Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"\t features.0.weight\n\t features.0.bias\n\t features.3.weight\n\t features.3.bias\n\t features.6.weight\n\t features.6.bias\n\t features.8.weight\n\t features.8.bias\n\t features.10.weight\n\t features.10.bias\n\t classifier.1.weight\n\t classifier.1.bias\n\t classifier.4.weight\n\t classifier.4.bias\n\t classifier.6.weight\n\t classifier.6.bias\n","output_type":"stream"}]},{"cell_type":"code","source":"#define trainloader and test loader\nalex_trainloader = load_data('../output/kaggle/working/dataset224', '/train', 64)\nalex_testloader = load_data('../output/kaggle/working/dataset224', '/val', 64)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T16:38:45.150369Z","iopub.execute_input":"2022-02-11T16:38:45.150627Z","iopub.status.idle":"2022-02-11T16:38:45.353150Z","shell.execute_reply.started":"2022-02-11T16:38:45.150599Z","shell.execute_reply":"2022-02-11T16:38:45.352363Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2022-02-11T13:47:55.584619Z","iopub.execute_input":"2022-02-11T13:47:55.585459Z","iopub.status.idle":"2022-02-11T13:47:55.589806Z","shell.execute_reply.started":"2022-02-11T13:47:55.585422Z","shell.execute_reply":"2022-02-11T13:47:55.589019Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train_model(alexnet, alex_trainloader, alex_testloader,criterion, optimizer, \"cpu\", num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T14:36:13.612966Z","iopub.execute_input":"2022-02-11T14:36:13.613292Z","iopub.status.idle":"2022-02-11T16:14:23.527618Z","shell.execute_reply.started":"2022-02-11T14:36:13.613251Z","shell.execute_reply":"2022-02-11T16:14:23.526836Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Epoch 0/9\n----------\nLoss: 0.2187 Acc: 0.9360\n\nEpoch 1/9\n----------\nLoss: 0.1170 Acc: 0.9682\n\nEpoch 2/9\n----------\nLoss: 0.0804 Acc: 0.9790\n\nEpoch 3/9\n----------\nLoss: 0.0224 Acc: 0.9953\n\nEpoch 4/9\n----------\nLoss: 0.0114 Acc: 0.9978\n\nEpoch 5/9\n----------\nLoss: 0.0023 Acc: 0.9999\n\nEpoch 6/9\n----------\nLoss: 0.0012 Acc: 0.9999\n\nEpoch 7/9\n----------\nLoss: 0.0008 Acc: 1.0000\n\nEpoch 8/9\n----------\nLoss: 0.0007 Acc: 1.0000\n\nEpoch 9/9\n----------\nLoss: 0.0005 Acc: 1.0000\n\nTraining complete in 98m 10s\nBest Acc: 1.000000\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"([0.9360150552811103,\n  0.9681643534854544,\n  0.978985336783502,\n  0.9952952246530228,\n  0.9978044381714106,\n  0.9999215870775504,\n  0.9999215870775504,\n  1.0,\n  1.0,\n  1.0],\n [0.21870696648405008,\n  0.11698300498757168,\n  0.08044734101033844,\n  0.022360630544272914,\n  0.011361772172486878,\n  0.0023292207765843688,\n  0.0012002615980524415,\n  0.0008452186057990594,\n  0.0006666940712019044,\n  0.0005476485426589506],\n AlexNet(\n   (features): Sequential(\n     (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n     (1): ReLU(inplace=True)\n     (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n     (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n     (4): ReLU(inplace=True)\n     (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n     (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (7): ReLU(inplace=True)\n     (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (9): ReLU(inplace=True)\n     (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (11): ReLU(inplace=True)\n     (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n   )\n   (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n   (classifier): Sequential(\n     (0): Dropout(p=0.5, inplace=False)\n     (1): Linear(in_features=9216, out_features=4096, bias=True)\n     (2): ReLU(inplace=True)\n     (3): Dropout(p=0.5, inplace=False)\n     (4): Linear(in_features=4096, out_features=1024, bias=True)\n     (5): ReLU(inplace=True)\n     (6): Linear(in_features=1024, out_features=104, bias=True)\n   )\n ))"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nalexnet.load_state_dict(torch.load('../output/kaggle/working/temp/09.pth'))\n\npredictions=[]\nlbls=[]\nfor i, data in enumerate(alex_testloader, 0):\n    #Get inputs\n    inputs, labels = data\n    outputs = alexnet(inputs)\n    _, preds = torch.max(outputs, 1)\n    \n    predictions.append(preds)\n    lbls.append(labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T16:43:02.895250Z","iopub.execute_input":"2022-02-11T16:43:02.895514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-11T16:39:45.148698Z","iopub.execute_input":"2022-02-11T16:39:45.149436Z","iopub.status.idle":"2022-02-11T16:39:45.156458Z","shell.execute_reply.started":"2022-02-11T16:39:45.149400Z","shell.execute_reply":"2022-02-11T16:39:45.155773Z"}}},{"cell_type":"code","source":"lbls = np.asarray(lbls).flatten()\nprint(lbls)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T16:42:28.223057Z","iopub.execute_input":"2022-02-11T16:42:28.223815Z","iopub.status.idle":"2022-02-11T16:42:28.231333Z","shell.execute_reply.started":"2022-02-11T16:42:28.223756Z","shell.execute_reply":"2022-02-11T16:42:28.230614Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"[tensor([ 44,  48,   2,  72,  50,  51,  68,  47,  52,  57,   6,  53,   6,  48,\n          46,  40,  44,  75,  38,  25, 100,  41,  70,  22,  74,  68,  16,  15,\n          34, 103,  77,  46,  75,   9,   9,  44,  38,  39,   9,  44,   6,  63,\n          74, 100,  11,  77,  82,  77,  54,  68,  50,  85,  69,  99,  21,  94,\n          68, 100,  47,   2,   8,  48,  80,  72])\n tensor([ 85,  48,  98,  58,  55,  68,   0,  94,  65,  37,   6,  45,   6,   8,\n          77,  97,  75,   6,  94,   5,  75,  41,  74,  25,  45,  26,  25,   6,\n          90,  68,  48,  49,  99,  61,  46,  11,  38,  87,   5,  68,  51,  78,\n          53,  47,  69,   3, 100,  47,  48,   3,  48,  38,   6,  25,  56,  68,\n          72,   4,  38,   4,  50,   0,  38,  53])\n tensor([ 69,  50,  75,  48,  68,  99,  10,  38,  83,  58,  41,  41,  18,  73,\n          38,  96,  90,  26,  77,  80,  10,  97,  38,  97,  83, 100,  34,  44,\n          44,  85,  69,  33,  89,  23,  77,  75,  77,  68,  69,  95,   0,  28,\n          28,  10,   0,   4,  48,  40,  64,   6,   1,  14,   5,  26,  10,  48,\n          42,  95,  53,  78,  53,  15,  18,  54])\n ...\n tensor([ 48,  99, 100,  77,  38,  86,  47,  68,  68,  85,  45,  75,  89,  37,\n          18,  42,   6,  63,  38,   6,  51,  43,  40,  44,  37,   5,  98,  75,\n          77,   6,   5,  83,   0,  68,  38,   0,  47,  56,  10,  56,  51,   6,\n          44,  85,  48,  56,  69,  68,  87,  97,  10,  97,  28,  23,  74,  30,\n          38,  10,  86,  82,  99,  47,  68,  47])\n tensor([ 38,  75,  52,  50,  14,  68,  77,  22,   5,  84,  68,  65,  48,  86,\n          47,  66,  56,  68,  52,  68,  75,  26,  68,   5,  47,  71, 101,  77,\n           6,  69,  77,  63,  71,  53,  95,  94,  63,  53,  94,  97,   0,  47,\n          80,  38,   6,  12,  77,  97,  86,  28,  40,  68,   6,  99,   5,  13,\n          44,  57,  68,  48,  38,  91,  51,  46])\n tensor([82, 75, 90,  6, 72, 97, 69, 75, 72, 48, 56,  5,  6, 22, 69, 38,  9])]\n","output_type":"stream"}]},{"cell_type":"code","source":"cm = confusion_matrix(lbls, predictions)\nscore=torch.sum(predictions == lbls)\nprecision=np.diag(cm) / np.sum(cm, axis=0)\nrecall=np.diag(cm) / np.sum(cm, axis=1)\n\ndisplay_confusion_matrix(cm, score, precision, recall)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T16:42:11.539339Z","iopub.execute_input":"2022-02-11T16:42:11.539591Z","iopub.status.idle":"2022-02-11T16:42:11.568563Z","shell.execute_reply.started":"2022-02-11T16:42:11.539563Z","shell.execute_reply":"2022-02-11T16:42:11.567627Z"},"trusted":true},"execution_count":73,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2129712056.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlbls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [200, 12753]"],"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [200, 12753]","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}